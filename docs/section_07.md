# **Scikit-Learn**

[Scikit-learn](https://scikit-learn.org/stable/user_guide.html) es una de las bibliotecas m谩s populares de Python para Machine Learning. Ofrece herramientas simples y eficientes para el an谩lisis de datos y modelado predictivo. Compatible con NumPy, pandas y matplotlib, es ideal para **construir y evaluar modelos de Machine Learning**.

---

## **ndice**

1. [驴Qu茅 es Machine Learning?](#1-qu茅-es-machine-learning)
2. [驴Qu茅 es Scikit-Learn?](#2-qu茅-es-scikit-learn)
3. [Workflow en Scikit-Learn](#3-workflow-en-scikit-learn)
4. [Debugging Warnings en Jupyter](#4-debugging-warnings-en-jupyter)
5. [Divisi贸n de Datos (Splitting Data)](#5-divisi贸n-de-datos-splitting-data)
6. [Limpieza y Transformaci贸n de Datos](#6-limpieza-y-transformaci贸n-de-datos-clean-transform-reduce)
7. [Convertir Datos en N煤meros](#7-convertir-datos-en-n煤meros)
8. [Manejo de Valores Faltantes](#8-manejo-de-valores-faltantes)
9. [Escalado de Caracter铆sticas (Feature Scaling)](#9-escalado-de-caracter铆sticas-feature-scaling)
10. [Elegir el Modelo Correcto (Regresi贸n)](#10-elegir-el-modelo-correcto-regresi贸n)
11. [rboles de Decisi贸n (Decision Trees)](#10-谩rboles-de-decisi贸n-decision-trees)
12. [Funcionamiento de los Algoritmos de ML](#11-funcionamiento-de-los-algoritmos-de-ml)
13. [Elegir el Modelo Correcto (Clasificaci贸n)](#12-elegir-el-modelo-correcto-clasificaci贸n)
14. [Ajustar un Modelo a los Datos](#13-ajustar-un-modelo-a-los-datos)
15. [Predicciones con un Modelo](#14-predicciones-con-un-modelo)
16. [Evaluaci贸n de Modelos de Machine Learning](#15-evaluaci贸n-de-modelos-de-machine-learning)
17. [Mejorar un Modelo de Machine Learning](#16-mejorar-un-modelo-de-machine-learning)
18. [Guardar y Cargar Modelos](#17-guardar-y-cargar-modelos)
19. [Resumen Completo y Pr谩ctica Final](#18-resumen-completo-y-pr谩ctica-final)

> [!NOTE] > **驴C贸mo obtener ayuda?**
>
> - **Experimenta:** Usa lo que sabes y prueba. Aprender haciendo es clave en ML.
> - **SHIFT + TAB:** Usa esta funci贸n en Jupyter para obtener informaci贸n sobre una funci贸n o m茅todo.
> - **Busca online:** Investiga en la documentaci贸n de [Scikit-Learn](<(https://scikit-learn.org/stable/user_guide.html)>) o en Stack Overflow.
> - **Pregunta:** Si te atascas, pregunta en foros o comunidades de Machine Learning.

---

## **1. 驴Qu茅 es Machine Learning?**

Machine Learning (ML) es una rama de la inteligencia artificial que permite a las m谩quinas **aprender patrones de datos sin ser expl铆citamente programadas.**

- **Tipos de ML:**
  - **Supervisado:** Entrenado con datos etiquetados (ej. predicci贸n de precios).
  - **No supervisado:** Identifica patrones en datos sin etiquetas (ej. clustering).
  - **Aprendizaje por refuerzo:** Aprende interactuando con el entorno para maximizar recompensas.

<img src="../assets/section-7/machine-learning.webp" alt="Qu茅 es machine learning" width="800" style="padding:24px; margin: 24px auto; background: white;">

---

## **2. 驴Qu茅 es Scikit-Learn?**

**Scikit-Learn**, com煤nmente llamado `sklearn`, es una biblioteca de c贸digo abierto de Python para Machine Learning.

Est谩 construido sobre:

- **NumPy:** Biblioteca de Python para c谩lculos num茅ricos.
- **Matplotlib:** Biblioteca para visualizaci贸n de datos.

Ofrece herramientas para realizar todas las etapas principales de un proyecto de Machine Learning, desde la preparaci贸n de datos hasta la construcci贸n y evaluaci贸n de modelos.

### 驴Por qu茅 usar Scikit-Learn?

El objetivo principal del Machine Learning es **encontrar patrones en los datos** y usar esos patrones para hacer **predicciones**.

Algunos tipos comunes de problemas de Machine Learning incluyen:

- **Clasificaci贸n:** Predecir una categor铆a (ej. si un email es spam o no).
- **Regresi贸n:** Predecir un n煤mero (ej. precio de casas).
- **Clustering:** Agrupar elementos similares sin etiquetas previas.

Para cualquier problema, las etapas son similares:

1. Dividir los datos en conjuntos de entrenamiento y prueba.
2. Elegir un modelo.
3. Ajustar el modelo a los datos.
4. Evaluar el modelo para ver si ha aprendido algo.

Scikit-Learn ofrece implementaciones en Python para realizar todas estas tareas, evitando la necesidad de construirlas desde cero.

---

## **3. Workflow en Scikit-Learn**

1. **Obtener y preparar los datos**
2. **Dividir los datos**
   - en caracter铆sticas (`X`) y etiquetas (`Y`)
   - en conjuntos de entrenamiento y prueba
3. **Elegir un modelo y sus hiperpar谩metros**
   - Clasificaci贸n : `RandomForestClassifier`, `LogisticRegression`, `SVC`.
   - Regresi贸n: `LinearRegression`, `RandomRegressor`.
4. **Ajustar el modelo** a los datos de entrenamiento
5. **Hacer predicciones**: predice etiquetas en datos no vistos
6. **Evaluar el modelo**
   - Clasificaci贸n: Usa m茅tricas como precisi贸n, matriz de confusi贸n, etc.
   - Regresi贸n: Usa m茅tricas como `r2_score`, `mean_squared_error`.
7. **Experimentar y mejorar** el modelo si es necesario
   - Ajusta los hiperpar谩metros con `GridSerachCV`o prueba modelos m谩s avanzados.
   - Experimenta con diferentes t茅cnicas de preprocesamiento.
8. **Guardar y cargar el modelo**

```python
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error

# Ejemplo simple de workflow
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # Dividir los datos
model = LinearRegression() # Modelo elegido
model.fit(X_train, y_train) # Ajustar el modelo
predictions = model.predict(X_test) # Hacer predicciones
error = mean_absolute_error(y_test, predictions) # Evaluar el modelo
```

---

## **4. Debugging Warnings en Jupyter**

Mientras trabajas en Jupyter Notebook, puedes encontrarte con **mensajes de advertencia** que te alertan sobre **posibles problemas o cambios futuros** en las bibliotecas que utilizas. Estos mensajes son 煤tiles para mejorar tu c贸digo, pero a veces pueden ser molestos si est谩s experimentando o trabajando con c贸digo heredado.

### **Tipos comunes de advertencias**

1. **`FutureWarning`:** Indica que algo en tu c贸digo ser谩 obsoleto en una versi贸n futura.
2. **`DeprecationWarning`:** Similar a `FutureWarning`, pero se usa para elementos que ya est谩n obsoletos.
3. **`UserWarning`:** Mensajes de advertencia personalizados o relacionados con configuraciones espec铆ficas.

### **C贸mo manejar advertencias en Scikit-Learn**

1. **Lee el mensaje de advertencia completo:**

   - Identifica qu茅 est谩 causando la advertencia. Por ejemplo:
     ```
     FutureWarning: The parameter 'normalize' in function 'LinearRegression' is deprecated and will be removed in version 1.2. Please use 'StandardScaler' instead.
     ```
   - Esto sugiere reemplazar `normalize=True` por el uso de `StandardScaler`.

2. **Consulta la documentaci贸n oficial:**

   - La advertencia suele mencionar una soluci贸n recomendada. Busca el t茅rmino o funci贸n en la [documentaci贸n oficial de Scikit-Learn](https://scikit-learn.org/stable/documentation.html).

3. **Actualiza tu c贸digo para evitar advertencias futuras:**

   - Adapta tu c贸digo siguiendo las recomendaciones.
   - Ejemplo de correcci贸n:

     ```python
     # Antes (genera FutureWarning)
     from sklearn.linear_model import LinearRegression
     model = LinearRegression(normalize=True)

     # Despu茅s (soluci贸n recomendada)
     from sklearn.pipeline import make_pipeline
     from sklearn.preprocessing import StandardScaler
     model = make_pipeline(StandardScaler(), LinearRegression())
     ```

4. **Ignorar advertencias temporalmente:**

   - Si necesitas ignorar advertencias durante el desarrollo, puedes usar:
     ```python
     import warnings
     warnings.filterwarnings("ignore", category=FutureWarning)
     ```
     Esto suprime **solo** los mensajes de `FutureWarning`.

5. **Habilitar advertencias para depuraci贸n:**
   - Si necesitas volver a habilitar las advertencias:
     ```python
     warnings.filterwarnings("default")
     ```

#### **Ejemplo pr谩ctico para `FutureWarning` en Scikit-Learn**

Si est谩s trabajando con una versi贸n m谩s antigua de Scikit-Learn y ves un `FutureWarning`, actualiza la biblioteca para evitar el problema:

```bash
pip install -U scikit-learn
```

### **Actualizar Scikit-Learn con conda**

Si est谩s usando **conda** como gestor de entornos, puedes actualizar **Scikit-Learn** y otras bibliotecas directamente desde la terminal. Aqu铆 tienes los pasos para hacerlo:

1. **Activar el entorno Conda:**
   Primero aseg煤rate de activar el entorno en el que deseas actualizar Scikit-Learn:

   ```bash
   conda activate nombre_del_entorno
   ```

2. **Actualizar Scikit-Learn:**
   Ejecuta el siguiente comando para actualizar Scikit-Learn a la 煤ltima versi贸n disponible en los canales de Conda:

   ```bash
   conda update scikit-learn
   ```

3. **Confirmar la instalaci贸n:**
   Si Conda encuentra una versi贸n m谩s reciente, pedir谩 confirmaci贸n para actualizar. Escribe `y` y presiona **Enter** para proceder.

#### **Actualizar Scikit-Learn a una versi贸n espec铆fica:**

Si necesitas una versi贸n espec铆fica de Scikit-Learn, usa:

```bash
conda install scikit-learn=1.2.0
```

(Reemplaza `1.2.0` con la versi贸n que necesites.)

#### **Actualizar todo el entorno Conda**

Si prefieres actualizar todas las bibliotecas de tu entorno al mismo tiempo, puedes usar:

```bash
conda update --all
```

#### **Verificar la versi贸n instalada**

Despu茅s de actualizar, verifica que tienes la versi贸n correcta:

```python
import sklearn
print(sklearn.__version__)
```

> [!Note] > **Notas importantes**
>
> - Si no encuentras la versi贸n m谩s reciente de Scikit-Learn en los canales predeterminados de Conda, puedes intentar instalarla desde el canal `conda-forge`:
>
> ```bash
> conda install -c conda-forge scikit-learn
> ```
>
> - Actualizar Scikit-Learn puede requerir actualizar otras bibliotecas como **NumPy** y **SciPy**, ya que Scikit-Learn depende de ellas. Conda manejar谩 estas dependencias autom谩ticamente.
> - Si no puedes actualizar, puedes ignorar las advertencias de forma temporal o adaptarte a las nuevas recomendaciones que aparecen en la advertencia.

#### **Buenas pr谩cticas**

- Usa `warnings.filterwarnings("ignore")` solo como 煤ltima opci贸n o mientras experimentas.
- Actualiza tus bibliotecas regularmente para evitar problemas de compatibilidad.
- Consulta siempre la documentaci贸n oficial y las notas de la versi贸n:
  -  [Notas de versi贸n de Scikit-Learn](https://scikit-learn.org/stable/whats_new.html).

---

## **5. Divisi贸n de Datos (Splitting Data)**

Un paso crucial en cualquier proyecto de machine learning es dividir los datos en conjuntos de entrenamiento y prueba para evaluar c贸mo se comporta el modelo con datos no vistos.

La funci贸n `train_test_split` de Scikit-Learn divide los datos en dos o m谩s conjuntos:

- **Entrenamiento (`train`):** Datos que el modelo utiliza para aprender patrones.
- **Prueba (`test`):** Datos reservados para evaluar el modelo despu茅s del entrenamiento.

Ejemplo b谩sico:

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,  # Proporci贸n del conjunto de prueba (20%)
    random_state=42 # Fijar semilla para resultados reproducibles
)
```

- **`test_size`:** Define el porcentaje de datos asignados al conjunto de prueba.
- **`random_state`:** Asegura que los datos se dividan de la misma forma en cada ejecuci贸n, 煤til para experimentos reproducibles.

---

## **6. Limpieza y Transformaci贸n de Datos (Clean, Transform, Reduce)**

#### **1. Limpieza (`Clean`):**

- Elimina valores faltantes o err贸neos para evitar que distorsionen los resultados del modelo.
- Por ejemplo, puedes usar Pandas para eliminar filas con valores nulos:
  ```python
  X.dropna(inplace=True)
  ```

#### **2. Transformaci贸n (`Transform`):**

- Convierte los datos a formatos adecuados, como escalar valores num茅ricos o codificar variables categ贸ricas.
- Ejemplo: Escalar caracter铆sticas num茅ricas usando `StandardScaler`:
  ```python
  from sklearn.preprocessing import StandardScaler
  scaler = StandardScaler()
  X_scaled = scaler.fit_transform(X)
  ```

#### **3. Reducci贸n (`Reduce`):**

- Simplifica los datos, por ejemplo, reduciendo la dimensionalidad con PCA si el conjunto de datos tiene muchas caracter铆sticas.
- Ejemplo:
  ```python
  from sklearn.decomposition import PCA
  pca = PCA(n_components=2)
  X_reduced = pca.fit_transform(X)
  ```

> [!NOTE] > **Nota Pr谩ctica**
>
> - Una divisi贸n mal realizada puede generar un modelo que no generalice bien.
> - Si los datos son muy peque帽os, considera **validaci贸n cruzada** en lugar de dividir en `train/test`.
> - Siempre inspecciona los datos despu茅s de dividirlos para garantizar que los conjuntos sean representativos:
>
> ```python
> print(X_train.shape, X_test.shape)
> print(y_train.value_counts(), y_test.value_counts())
> ```

---

Claro, aqu铆 tienes una explicaci贸n m谩s detallada y 煤til sobre c贸mo trabajar con datos categ贸ricos y convertirlos a n煤meros:

---

## **7. Convertir Datos en N煤meros**

Los algoritmos de machine learning suelen trabajar mejor con datos num茅ricos. Sin embargo, en muchos casos, los datos contienen **variables categ贸ricas** (como colores, pa铆ses, tipos de productos, etc.). Para convertir estos datos categ贸ricos en n煤meros, Scikit-Learn proporciona herramientas como `LabelEncoder` y `OneHotEncoder`.

### **1. `LabelEncoder`**

El `LabelEncoder` asigna un n煤mero 煤nico a cada categor铆a de una columna. Este m茅todo es 煤til cuando las categor铆as tienen un **orden l贸gico**, como "bajo", "medio", "alto".

Ejemplo:

```python
from sklearn.preprocessing import LabelEncoder

data = pd.DataFrame({"color": ["red", "blue", "green", "blue", "red"]})

label_encoder = LabelEncoder()
data["color_encoded"] = label_encoder.fit_transform(data["color"])
print(data)
```

**Salida:**

```plaintext
   color  color_encoded
0    red              2
1   blue              0
2  green              1
3   blue              0
4    red              2
```

- **Ventajas:** Simple y directo.
- **Desventajas:** Puede inducir relaciones ordinales incorrectas entre las categor铆as si no hay un orden l贸gico.

### **2. `OneHotEncoder`**

El `OneHotEncoder` crea columnas binarias (0 o 1) para cada categor铆a, evitando que el modelo asuma relaciones ordinales entre categor铆as.

<img src="../assets/section-7/one_hot_encoding.png" alt="One Hot Encoding" width="800" style="padding:24px; margin: 24px auto; background: white;">

Ejemplo:

```python
from sklearn.preprocessing import OneHotEncoder

data = pd.DataFrame({"color": ["red", "blue", "green", "blue", "red"]})

one_hot_encoder = OneHotEncoder()
encoded = one_hot_encoder.fit_transform(data[["color"]])
print(encoded.toarray())  # Convertir a matriz NumPy para ver los resultados
```

**Salida:**

```plaintext
[[0. 0. 1.]
 [1. 0. 0.]
 [0. 1. 0.]
 [1. 0. 0.]
 [0. 0. 1.]]
```

- Las columnas representan categor铆as en orden alfab茅tico: `["blue", "green", "red"]`.
- **Ventajas:** Evita relaciones ordinales falsas.
- **Desventajas:** Incrementa el tama帽o del dataset si hay muchas categor铆as.

> [!NOTE]
>
> - En una versi贸n m谩s nueva de Scikit-Learn (0.23+), la clase `OneHotEncoder` puede manejar valores `None` y `NaN`.
> -  [Documentaci贸n OneHotEncoder Scikit-Learn](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)

### **3. Usar `ColumnTransformer` con `OneHotEncoder`**

Si tienes varias columnas categ贸ricas y num茅ricas en tu dataset, puedes usar `ColumnTransformer` para aplicar transformaciones espec铆ficas a cada tipo de columna.

Ejemplo pr谩ctico:

```python
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder

data = pd.DataFrame({
    "color": ["red", "blue", "green", "blue", "red"],
    "size": ["S", "M", "L", "M", "S"],
    "price": [10, 20, 15, 25, 30]
})

categorical_features = ["color", "size"]
one_hot_encoder = OneHotEncoder()

transformer = ColumnTransformer(
   transformers=[("one_hot", one_hot_encoder, categorical_features)],
   remainder="passthrough"  # Deja las columnas no especificadas sin cambios
)

transformed_data = transformer.fit_transform(data)
print(transformed_data)
```

**Salida:**

```plaintext
[[0. 0. 1. 1. 0. 0. 10.]
 [1. 0. 0. 0. 1. 0. 20.]
 [0. 1. 0. 0. 0. 1. 15.]
 [1. 0. 0. 0. 1. 0. 25.]
 [0. 0. 1. 1. 0. 0. 30.]]
```

### **Tips para elegir el m茅todo adecuado:**

1. Usa `LabelEncoder` si tus categor铆as tienen un **orden l贸gico** o si son simples y est谩n contenidas en una 煤nica columna.
2. Usa `OneHotEncoder` si quieres evitar relaciones ordinales falsas entre categor铆as.
3. Si trabajas con datasets m谩s complejos (mixtos con columnas categ贸ricas y num茅ricas), utiliza `ColumnTransformer` para combinar transformaciones.

Esto hace que tus datos est茅n listos para ser utilizados por algoritmos de machine learning que requieren representaciones num茅ricas.

---

## **8. Manejo de Valores Faltantes**

### Con pandas:

```python
df["column"] = df["column"].fillna(value)
```

### Con Scikit-Learn:

```python
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy="mean")
imputed = imputer.fit_transform(df)
```

---

## **9. Escalado de Caracter铆sticas (Feature Scaling)**

Una vez que tus datos est茅n en formato num茅rico, probablemente querr谩s aplicarles una transformaci贸n adicional: **escalado de caracter铆sticas (Feature Scaling)**. Esto significa asegurarte de que **todos los datos num茅ricos est茅n en la misma escala**.

**驴Por qu茅 es importante?**

Imagina que est谩s tratando de predecir el precio de venta de coches y el kilometraje var铆a entre 6,000 y 345,000, mientras que el costo promedio de reparaciones anteriores var铆a entre 100 y 1,700. Un algoritmo de aprendizaje autom谩tico podr铆a tener dificultades para encontrar patrones en estas variables con rangos tan diferentes.

Para solucionar esto, existen dos tipos principales de escalado de caracter铆sticas:

1. **Normalizaci贸n (`MinMaxScaler`):**

   - Este m茅todo reescala todos los valores num茅ricos para que est茅n entre 0 y 1.
   - El valor m谩s bajo estar谩 cerca de 0, y el m谩s alto estar谩 cerca de 1.
   - [Scikit-Learn proporciona la clase `MinMaxScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) para realizar esta operaci贸n.

2. **Estandarizaci贸n (`StandardScaler`):**

   - Este m茅todo resta la media de cada caracter铆stica, de modo que los valores resultantes tengan una media de 0.
   - Luego escala las caracter铆sticas a varianza unitaria (dividiendo por la desviaci贸n est谩ndar).
   - [Scikit-Learn proporciona la clase `StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) para esta tarea.

   ```python
   from sklearn.preprocessing import StandardScaler
   scaler = StandardScaler()
   scaled_data = scaler.fit_transform(data)
   ```

> [!NOTE] **Notas importantes:**
>
> - El **escalado de caracter铆sticas generalmente no se aplica a la variable objetivo** (la que intentas predecir).
> - El **escalado de caracter铆sticas no suele ser necesario en modelos basados en 谩rboles** (por ejemplo, Random Forest), ya que estos pueden manejar caracter铆sticas con diferentes escalas.

** Lectura adicional**

- **[Feature Scaling - why is it required?](https://rahul-saini.medium.com/feature-scaling-why-it-is-required-8a93df1af310)** por Rahul Saini.
- **[Feature Scaling with Scikit-Learn](https://benalexkeen.com/feature-scaling-with-scikit-learn/)** por Ben Alex Keen.
- **[Feature Scaling for Machine Learning: Understanding the Difference Between Normalization vs. Standardization](https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/)** por Aniruddha Bhandari.

---

## **9. Elegir el Modelo Correcto (Regresi贸n)**

- Modelos comunes para regresi贸n:
  - `LinearRegression`
  - `Ridge`
  - `RandomForestRegressor`

---

## **10. rboles de Decisi贸n (Decision Trees)**

Un modelo que utiliza reglas condicionales para dividir los datos en ramas.

```python
from sklearn.tree import DecisionTreeClassifier
model = DecisionTreeClassifier()
```

---

## **11. Funcionamiento de los Algoritmos de ML**

### Tipos:

- Algoritmos lineales (ej. regresi贸n lineal).
- Modelos basados en 谩rboles (ej. Random Forest).
- Redes neuronales para datos complejos.

---

## **12. Elegir el Modelo Correcto (Clasificaci贸n)**

- Modelos comunes para clasificaci贸n:
  - `LogisticRegression`
  - `SVC`
  - `RandomForestClassifier`

---

## **13. Ajustar un Modelo a los Datos**

```python
model.fit(X_train, y_train)
```

---

## **14. Predicciones con un Modelo**

```python
predictions = model.predict(X_test)
```

---

## **15. Evaluaci贸n de Modelos de Machine Learning**

### Clasificaci贸n:

- `accuracy_score`
- `confusion_matrix`
- `classification_report`

### Regresi贸n:

- `r2_score`
- `mean_absolute_error`
- `mean_squared_error`

---

## **16. Mejorar un Modelo de Machine Learning**

- Ajustar hiperpar谩metros con `GridSearchCV`.
- A帽adir m谩s datos o limpiar los existentes.

---

## **17. Guardar y Cargar Modelos**

```python
import joblib
joblib.dump(model, 'model.pkl')
loaded_model = joblib.load('model.pkl')
```

---

## **18. Resumen Completo y Pr谩ctica Final**

Integra todos los pasos para resolver un problema completo de Machine Learning:

1. Limpia y transforma los datos.
2. Divide los datos.
3. Escala caracter铆sticas.
4. Ajusta un modelo.
5. Eval煤a su desempe帽o.
6. Mejora si es necesario.

---

Este archivo est谩 dise帽ado para que sea un recurso pr谩ctico y 煤til a medida que avances en tu aprendizaje con Scikit-learn.
