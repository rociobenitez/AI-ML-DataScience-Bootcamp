# **Scikit-Learn**

[Scikit-learn](https://scikit-learn.org/stable/user_guide.html) es una de las bibliotecas m谩s populares de Python para Machine Learning. Ofrece herramientas simples y eficientes para el an谩lisis de datos y modelado predictivo. Compatible con NumPy, pandas y matplotlib, es ideal para **construir y evaluar modelos de Machine Learning**.

---

## **ndice**

1. [驴Qu茅 es Machine Learning?](#1-qu茅-es-machine-learning)
2. [驴Qu茅 es Scikit-Learn?](#2-qu茅-es-scikit-learn)
3. [Workflow en Scikit-Learn](#3-workflow-en-scikit-learn)
4. [Debugging Warnings en Jupyter](#4-debugging-warnings-en-jupyter)
5. [Divisi贸n de Datos (Splitting Data)](#5-divisi贸n-de-datos-splitting-data)
6. [Limpieza y Transformaci贸n de Datos](#6-limpieza-y-transformaci贸n-de-datos-clean-transform-reduce)
7. [Convertir Datos en N煤meros](#7-convertir-datos-en-n煤meros)
8. [Manejo de Valores Faltantes](#8-manejo-de-valores-faltantes)
9. [Escalado de Caracter铆sticas (Feature Scaling)](#9-escalado-de-caracter铆sticas-feature-scaling)
10. [Elegir el Modelo Correcto](#10-elegir-el-modeloestimador-adecuado)
11. [rboles de Decisi贸n (Decision Trees)](#11-谩rboles-de-decisi贸n)
12. [Modelos de Ensamblaje](#12-modelos-de-ensamblaje)
13. [Ajustar un Modelo a los Datos](#13-ajustar-un-modelo-a-los-datos)
14. [Hacer Predicciones con un Modelo](#14-predicciones-con-un-modelo)
15. [Evaluaci贸n de Modelos de Machine Learning](#15-evaluaci贸n-de-modelos-de-machine-learning)
17. [Mejorar un Modelo de Machine Learning](#16-mejorar-un-modelo-de-machine-learning)
18. [Guardar y Cargar Modelos](#17-guardar-y-cargar-modelos)
19. [Resumen Completo y Pr谩ctica Final](#18-resumen-completo-y-pr谩ctica-final)

> [!NOTE] > **驴C贸mo obtener ayuda?**
>
> - **Experimenta:** Usa lo que sabes y prueba. Aprender haciendo es clave en ML.
> - **SHIFT + TAB:** Usa esta funci贸n en Jupyter para obtener informaci贸n sobre una funci贸n o m茅todo.
> - **Busca online:** Investiga en la documentaci贸n de [Scikit-Learn](<(https://scikit-learn.org/stable/user_guide.html)>) o en Stack Overflow.
> - **Pregunta:** Si te atascas, pregunta en foros o comunidades de Machine Learning.

---

## **1. 驴Qu茅 es Machine Learning?**

Machine Learning (ML) es una rama de la inteligencia artificial que permite a las m谩quinas **aprender patrones de datos sin ser expl铆citamente programadas.**

- **Tipos de ML:**
  - **Supervisado:** Entrenado con datos etiquetados (ej. predicci贸n de precios).
  - **No supervisado:** Identifica patrones en datos sin etiquetas (ej. clustering).
  - **Aprendizaje por refuerzo:** Aprende interactuando con el entorno para maximizar recompensas.

<img src="../assets/section-7/machine-learning.webp" alt="Qu茅 es machine learning" width="400" style="padding:24px; margin: 24px auto; background: white;">

## **2. 驴Qu茅 es Scikit-Learn?**

**Scikit-Learn**, com煤nmente llamado `sklearn`, es una biblioteca de c贸digo abierto de Python para Machine Learning.

Est谩 construido sobre:

- **NumPy:** Biblioteca de Python para c谩lculos num茅ricos.
- **Matplotlib:** Biblioteca para visualizaci贸n de datos.

Ofrece herramientas para realizar todas las etapas principales de un proyecto de Machine Learning, desde la preparaci贸n de datos hasta la construcci贸n y evaluaci贸n de modelos.

### 驴Por qu茅 usar Scikit-Learn?

El objetivo principal del Machine Learning es **encontrar patrones en los datos** y usar esos patrones para hacer **predicciones**.

Algunos tipos comunes de problemas de Machine Learning incluyen:

- **Clasificaci贸n:** Predecir una categor铆a (ej. si un email es spam o no).
- **Regresi贸n:** Predecir un n煤mero (ej. precio de casas).
- **Clustering:** Agrupar elementos similares sin etiquetas previas.

Para cualquier problema, las etapas son similares:

1. Dividir los datos en conjuntos de entrenamiento y prueba.
2. Elegir un modelo.
3. Ajustar el modelo a los datos.
4. Evaluar el modelo para ver si ha aprendido algo.

Scikit-Learn ofrece implementaciones en Python para realizar todas estas tareas, evitando la necesidad de construirlas desde cero.

## **3. Workflow en Scikit-Learn**

1. **Obtener y preparar los datos**
2. **Dividir los datos**
   - en caracter铆sticas (`X`) y etiquetas (`Y`)
   - en conjuntos de entrenamiento y prueba
3. **Elegir un modelo y sus hiperpar谩metros**
   - Clasificaci贸n : `RandomForestClassifier`, `LogisticRegression`, `SVC`.
   - Regresi贸n: `LinearRegression`, `RandomRegressor`.
4. **Ajustar el modelo** a los datos de entrenamiento
5. **Hacer predicciones**: predice etiquetas en datos no vistos
6. **Evaluar el modelo**
   - Clasificaci贸n: Usa m茅tricas como precisi贸n, matriz de confusi贸n, etc.
   - Regresi贸n: Usa m茅tricas como `r2_score`, `mean_squared_error`.
7. **Experimentar y mejorar** el modelo si es necesario
   - Ajusta los hiperpar谩metros con `GridSerachCV`o prueba modelos m谩s avanzados.
   - Experimenta con diferentes t茅cnicas de preprocesamiento.
8. **Guardar y cargar el modelo**

```python
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error

# Ejemplo simple de workflow
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # Dividir los datos
model = LinearRegression() # Modelo elegido
model.fit(X_train, y_train) # Ajustar el modelo
predictions = model.predict(X_test) # Hacer predicciones
error = mean_absolute_error(y_test, predictions) # Evaluar el modelo
```

## **4. Debugging Warnings en Jupyter**

Mientras trabajas en Jupyter Notebook, puedes encontrarte con **mensajes de advertencia** que te alertan sobre **posibles problemas o cambios futuros** en las bibliotecas que utilizas. Estos mensajes son 煤tiles para mejorar tu c贸digo, pero a veces pueden ser molestos si est谩s experimentando o trabajando con c贸digo heredado.

### **Tipos comunes de advertencias**

1. **`FutureWarning`:** Indica que algo en tu c贸digo ser谩 obsoleto en una versi贸n futura.
2. **`DeprecationWarning`:** Similar a `FutureWarning`, pero se usa para elementos que ya est谩n obsoletos.
3. **`UserWarning`:** Mensajes de advertencia personalizados o relacionados con configuraciones espec铆ficas.

### **C贸mo manejar advertencias en Scikit-Learn**

1. **Lee el mensaje de advertencia completo:**

   - Identifica qu茅 est谩 causando la advertencia. Por ejemplo:
     ```
     FutureWarning: The parameter 'normalize' in function 'LinearRegression' is deprecated and will be removed in version 1.2. Please use 'StandardScaler' instead.
     ```
   - Esto sugiere reemplazar `normalize=True` por el uso de `StandardScaler`.

2. **Consulta la documentaci贸n oficial:**

   - La advertencia suele mencionar una soluci贸n recomendada. Busca el t茅rmino o funci贸n en la [documentaci贸n oficial de Scikit-Learn](https://scikit-learn.org/stable/documentation.html).

3. **Actualiza tu c贸digo para evitar advertencias futuras:**

   - Adapta tu c贸digo siguiendo las recomendaciones.
   - Ejemplo de correcci贸n:

     ```python
     # Antes (genera FutureWarning)
     from sklearn.linear_model import LinearRegression
     model = LinearRegression(normalize=True)

     # Despu茅s (soluci贸n recomendada)
     from sklearn.pipeline import make_pipeline
     from sklearn.preprocessing import StandardScaler
     model = make_pipeline(StandardScaler(), LinearRegression())
     ```

4. **Ignorar advertencias temporalmente:**

   - Si necesitas ignorar advertencias durante el desarrollo, puedes usar:
     ```python
     import warnings
     warnings.filterwarnings("ignore", category=FutureWarning)
     ```
     Esto suprime **solo** los mensajes de `FutureWarning`.

5. **Habilitar advertencias para depuraci贸n:**
   - Si necesitas volver a habilitar las advertencias:
     ```python
     warnings.filterwarnings("default")
     ```

#### **Ejemplo pr谩ctico para `FutureWarning` en Scikit-Learn**

Si est谩s trabajando con una versi贸n m谩s antigua de Scikit-Learn y ves un `FutureWarning`, actualiza la biblioteca para evitar el problema:

```bash
pip install -U scikit-learn
```

### **Actualizar Scikit-Learn con conda**

Si est谩s usando **conda** como gestor de entornos, puedes actualizar **Scikit-Learn** y otras bibliotecas directamente desde la terminal. Aqu铆 tienes los pasos para hacerlo:

1. **Activar el entorno Conda:**
   Primero aseg煤rate de activar el entorno en el que deseas actualizar Scikit-Learn:

   ```bash
   conda activate nombre_del_entorno
   ```

2. **Actualizar Scikit-Learn:**
   Ejecuta el siguiente comando para actualizar Scikit-Learn a la 煤ltima versi贸n disponible en los canales de Conda:

   ```bash
   conda update scikit-learn
   ```

3. **Confirmar la instalaci贸n:**
   Si Conda encuentra una versi贸n m谩s reciente, pedir谩 confirmaci贸n para actualizar. Escribe `y` y presiona **Enter** para proceder.

#### **Actualizar Scikit-Learn a una versi贸n espec铆fica:**

Si necesitas una versi贸n espec铆fica de Scikit-Learn, usa:

```bash
conda install scikit-learn=1.2.0
```

(Reemplaza `1.2.0` con la versi贸n que necesites.)

#### **Actualizar todo el entorno Conda**

Si prefieres actualizar todas las bibliotecas de tu entorno al mismo tiempo, puedes usar:

```bash
conda update --all
```

#### **Verificar la versi贸n instalada**

Despu茅s de actualizar, verifica que tienes la versi贸n correcta:

```python
import sklearn
print(sklearn.__version__)
```

> [!Note] > **Notas importantes**
>
> - Si no encuentras la versi贸n m谩s reciente de Scikit-Learn en los canales predeterminados de Conda, puedes intentar instalarla desde el canal `conda-forge`:
>
> ```bash
> conda install -c conda-forge scikit-learn
> ```
>
> - Actualizar Scikit-Learn puede requerir actualizar otras bibliotecas como **NumPy** y **SciPy**, ya que Scikit-Learn depende de ellas. Conda manejar谩 estas dependencias autom谩ticamente.
> - Si no puedes actualizar, puedes ignorar las advertencias de forma temporal o adaptarte a las nuevas recomendaciones que aparecen en la advertencia.

#### **Buenas pr谩cticas**

- Usa `warnings.filterwarnings("ignore")` solo como 煤ltima opci贸n o mientras experimentas.
- Actualiza tus bibliotecas regularmente para evitar problemas de compatibilidad.
- Consulta siempre la documentaci贸n oficial y las notas de la versi贸n:
  -  [Notas de versi贸n de Scikit-Learn](https://scikit-learn.org/stable/whats_new.html).

## **5. Divisi贸n de Datos (Splitting Data)**

Un paso crucial en cualquier proyecto de machine learning es dividir los datos en conjuntos de entrenamiento y prueba para evaluar c贸mo se comporta el modelo con datos no vistos.

La funci贸n `train_test_split` de Scikit-Learn divide los datos en dos o m谩s conjuntos:

- **Entrenamiento (`train`):** Datos que el modelo utiliza para aprender patrones.
- **Prueba (`test`):** Datos reservados para evaluar el modelo despu茅s del entrenamiento.

Ejemplo b谩sico:

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,  # Proporci贸n del conjunto de prueba (20%)
    random_state=42 # Fijar semilla para resultados reproducibles
)
```

- **`test_size`:** Define el porcentaje de datos asignados al conjunto de prueba.
- **`random_state`:** Asegura que los datos se dividan de la misma forma en cada ejecuci贸n, 煤til para experimentos reproducibles.

## **6. Limpieza y Transformaci贸n de Datos (Clean, Transform, Reduce)**

#### **Limpieza (`Clean`):**

- Elimina valores faltantes o err贸neos para evitar que distorsionen los resultados del modelo.
- Por ejemplo, puedes usar Pandas para eliminar filas con valores nulos:
  ```python
  X.dropna(inplace=True)
  ```

#### **Transformaci贸n (`Transform`):**

- Convierte los datos a formatos adecuados, como escalar valores num茅ricos o codificar variables categ贸ricas.
- Ejemplo: Escalar caracter铆sticas num茅ricas usando `StandardScaler`:
  ```python
  from sklearn.preprocessing import StandardScaler
  scaler = StandardScaler()
  X_scaled = scaler.fit_transform(X)
  ```

#### **Reducci贸n (`Reduce`):**

- Simplifica los datos, por ejemplo, reduciendo la dimensionalidad con PCA si el conjunto de datos tiene muchas caracter铆sticas.
- Ejemplo:
  ```python
  from sklearn.decomposition import PCA
  pca = PCA(n_components=2)
  X_reduced = pca.fit_transform(X)
  ```

> [!NOTE] > **Nota Pr谩ctica**
>
> - Una divisi贸n mal realizada puede generar un modelo que no generalice bien.
> - Si los datos son muy peque帽os, considera **validaci贸n cruzada** en lugar de dividir en `train/test`.
> - Siempre inspecciona los datos despu茅s de dividirlos para garantizar que los conjuntos sean representativos:
>
> ```python
> print(X_train.shape, X_test.shape)
> print(y_train.value_counts(), y_test.value_counts())
> ```

## **7. Convertir Datos en N煤meros**

Los algoritmos de machine learning suelen trabajar mejor con datos num茅ricos. Sin embargo, en muchos casos, los datos contienen **variables categ贸ricas** (como colores, pa铆ses, tipos de productos, etc.). Para convertir estos datos categ贸ricos en n煤meros, Scikit-Learn proporciona herramientas como `LabelEncoder` y `OneHotEncoder`.

### **1. `LabelEncoder`**

El `LabelEncoder` asigna un n煤mero 煤nico a cada categor铆a de una columna. Este m茅todo es 煤til cuando las categor铆as tienen un **orden l贸gico**, como "bajo", "medio", "alto".

Ejemplo:

```python
from sklearn.preprocessing import LabelEncoder

data = pd.DataFrame({"color": ["red", "blue", "green", "blue", "red"]})

label_encoder = LabelEncoder()
data["color_encoded"] = label_encoder.fit_transform(data["color"])
print(data)
```

**Salida:**

```plaintext
   color  color_encoded
0    red              2
1   blue              0
2  green              1
3   blue              0
4    red              2
```

- **Ventajas:** Simple y directo.
- **Desventajas:** Puede inducir relaciones ordinales incorrectas entre las categor铆as si no hay un orden l贸gico.

### **2. `OneHotEncoder`**

El `OneHotEncoder` crea columnas binarias (0 o 1) para cada categor铆a, evitando que el modelo asuma relaciones ordinales entre categor铆as.

<img src="../assets/section-7/one_hot_encoding.png" alt="One Hot Encoding" width="600" style="margin: 24px auto; background: white;">

Ejemplo:

```python
from sklearn.preprocessing import OneHotEncoder

data = pd.DataFrame({"color": ["red", "blue", "green", "blue", "red"]})

one_hot_encoder = OneHotEncoder()
encoded = one_hot_encoder.fit_transform(data[["color"]])
print(encoded.toarray())  # Convertir a matriz NumPy para ver los resultados
```

**Salida:**

```plaintext
[[0. 0. 1.]
 [1. 0. 0.]
 [0. 1. 0.]
 [1. 0. 0.]
 [0. 0. 1.]]
```

- Las columnas representan categor铆as en orden alfab茅tico: `["blue", "green", "red"]`.
- **Ventajas:** Evita relaciones ordinales falsas.
- **Desventajas:** Incrementa el tama帽o del dataset si hay muchas categor铆as.

> [!NOTE]
>
> - En una versi贸n m谩s nueva de Scikit-Learn (0.23+), la clase `OneHotEncoder` puede manejar valores `None` y `NaN`.
> -  [Documentaci贸n OneHotEncoder Scikit-Learn](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)

### **3. Usar `ColumnTransformer` con `OneHotEncoder`**

Si tienes varias columnas categ贸ricas y num茅ricas en tu dataset, puedes usar `ColumnTransformer` para aplicar transformaciones espec铆ficas a cada tipo de columna.

Ejemplo pr谩ctico:

```python
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder

data = pd.DataFrame({
    "color": ["red", "blue", "green", "blue", "red"],
    "size": ["S", "M", "L", "M", "S"],
    "price": [10, 20, 15, 25, 30]
})

categorical_features = ["color", "size"]
one_hot_encoder = OneHotEncoder()

transformer = ColumnTransformer(
   transformers=[("one_hot", one_hot_encoder, categorical_features)],
   remainder="passthrough"  # Deja las columnas no especificadas sin cambios
)

transformed_data = transformer.fit_transform(data)
print(transformed_data)
```

**Salida:**

```plaintext
[[0. 0. 1. 1. 0. 0. 10.]
 [1. 0. 0. 0. 1. 0. 20.]
 [0. 1. 0. 0. 0. 1. 15.]
 [1. 0. 0. 0. 1. 0. 25.]
 [0. 0. 1. 1. 0. 0. 30.]]
```

### **Tips para elegir el m茅todo adecuado:**

1. Usa `LabelEncoder` si tus categor铆as tienen un **orden l贸gico** o si son simples y est谩n contenidas en una 煤nica columna.
2. Usa `OneHotEncoder` si quieres evitar relaciones ordinales falsas entre categor铆as.
3. Si trabajas con datasets m谩s complejos (mixtos con columnas categ贸ricas y num茅ricas), utiliza `ColumnTransformer` para combinar transformaciones.

## **8. Manejo de Valores Faltantes**

### Con pandas:

```python
df["column"] = df["column"].fillna(value)
```

### Con Scikit-Learn:

```python
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy="mean")
imputed = imputer.fit_transform(df)
```

## **9. Escalado de Caracter铆sticas (Feature Scaling)**

Una vez que tus datos est茅n en formato num茅rico, probablemente querr谩s aplicarles una transformaci贸n adicional: **escalado de caracter铆sticas (Feature Scaling)**. Esto significa asegurarte de que **todos los datos num茅ricos est茅n en la misma escala**.

**驴Por qu茅 es importante?**

Imagina que est谩s tratando de predecir el precio de venta de coches y el kilometraje var铆a entre 6,000 y 345,000, mientras que el costo promedio de reparaciones anteriores var铆a entre 100 y 1,700. Un algoritmo de aprendizaje autom谩tico podr铆a tener dificultades para encontrar patrones en estas variables con rangos tan diferentes.

Para solucionar esto, existen dos tipos principales de escalado de caracter铆sticas:

1. **Normalizaci贸n (`MinMaxScaler`):**

   - Este m茅todo reescala todos los valores num茅ricos para que est茅n entre 0 y 1.
   - El valor m谩s bajo estar谩 cerca de 0, y el m谩s alto estar谩 cerca de 1.
   - [Scikit-Learn proporciona la clase `MinMaxScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) para realizar esta operaci贸n.

2. **Estandarizaci贸n (`StandardScaler`):**

   - Este m茅todo resta la media de cada caracter铆stica, de modo que los valores resultantes tengan una media de 0.
   - Luego escala las caracter铆sticas a varianza unitaria (dividiendo por la desviaci贸n est谩ndar).
   - [Scikit-Learn proporciona la clase `StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) para esta tarea.

   ```python
   from sklearn.preprocessing import StandardScaler
   scaler = StandardScaler()
   scaled_data = scaler.fit_transform(data)
   ```

> [!NOTE] **Notas importantes:**
>
> - El **escalado de caracter铆sticas generalmente no se aplica a la variable objetivo** (la que intentas predecir).
> - El **escalado de caracter铆sticas no suele ser necesario en modelos basados en 谩rboles** (por ejemplo, Random Forest), ya que estos pueden manejar caracter铆sticas con diferentes escalas.

** Lectura adicional**

- **[Feature Scaling - why is it required?](https://rahul-saini.medium.com/feature-scaling-why-it-is-required-8a93df1af310)** por Rahul Saini.
- **[Feature Scaling with Scikit-Learn](https://benalexkeen.com/feature-scaling-with-scikit-learn/)** por Ben Alex Keen.
- **[Feature Scaling for Machine Learning: Understanding the Difference Between Normalization vs. Standardization](https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/)** por Aniruddha Bhandari.

## **10. Elegir el modelo/estimador adecuado**

A menudo, la parte m谩s dif铆cil de resolver un problema de aprendizaje autom谩tico puede ser encontrar el estimador adecuado para el trabajo. Diferentes estimadores son m谩s adecuados para distintos tipos de datos y problemas.

Este [diagrama de flujo de Scikit-learn](https://scikit-learn.org/1.5/machine_learning_map.html) est谩 dise帽ado como una gu铆a aproximada para ayudar a los usuarios a abordar problemas en relaci贸n con qu茅 estimadores probar en sus datos. Puedes hacer clic en cualquier estimador del gr谩fico para ver su documentaci贸n. El emoji  debe interpretarse como *"si este estimador no logra el resultado deseado, sigue la flecha e intenta con el siguiente"*. 

<img src="../assets/section-7/ml_map.svg" alt="Diagrama de un rbol de decisi贸n" width="800" style="padding:24px; margin: 24px auto; background: white;">

## **11. rboles de Decisi贸n**

Un **rbol de Decisi贸n** es un modelo de machine learning que utiliza una estructura jer谩rquica de decisiones para dividir los datos en ramas seg煤n ciertas reglas condicionales. Se utiliza tanto en problemas de **clasificaci贸n** como de **regresi贸n**.

<img src="../assets/section-7/decision-tree.png" alt="Diagrama de un rbol de decisi贸n" width="500" style="padding:24px; margin: 24px auto; background: white;">

### **Caracter铆sticas principales**
- **F谩cil de interpretar:** La estructura de decisiones permite visualizar c贸mo el modelo llega a una conclusi贸n.
- **Capacidad de manejar datos categ贸ricos y num茅ricos.**
- **Propenso al overfitting:** Sin regularizaci贸n, los 谩rboles de decisi贸n pueden ajustarse demasiado a los datos de entrenamiento.

### **Implementaci贸n en Scikit-Learn**

```python
from sklearn.tree import DecisionTreeClassifier

# Crear el modelo
model = DecisionTreeClassifier()

# Entrenar el modelo
model.fit(X_train, y_train)

# Hacer predicciones
predictions = model.predict(X_test)
```

### **Visualizaci贸n de un rbol de Decisi贸n**

Puedes visualizar el 谩rbol utilizando `plot_tree` de Scikit-Learn:

```python
from sklearn.tree import plot_tree

plt.figure(figsize=(12, 8))
plot_tree(model, filled=True, feature_names=X.columns, class_names=["Clase 0", "Clase 1"])
plt.show()
```

## **12. Modelos de Ensamblaje**

Un **Modelo de Ensamblaje** combina m煤ltiples modelos (como 谩rboles de decisi贸n) para mejorar la precisi贸n, robustez y generalizaci贸n. 

### **Tipos de Modelos de Ensamblaje**
1. **Bagging (Bootstrap Aggregating):** Entrena varios modelos independientes (como 谩rboles de decisi贸n) en subconjuntos de los datos y combina sus predicciones (e.g., Random Forest).
2. **Boosting:** Entrena modelos secuencialmente, corrigiendo los errores del modelo anterior (e.g., Gradient Boosting, XGBoost).
3. **Stacking:** Combina diferentes tipos de modelos y utiliza otro modelo para aprender de sus predicciones.

### **Random Forest**

Un **Random Forest** es un tipo de modelo de ensamblaje basado en Bagging que combina m煤ltiples 谩rboles de decisi贸n. 

<img src="../assets/section-7/random_forest.png" alt="Random Forest Conceptual Diagram" width="500" style="margin: 16px auto; background: white;">

#### **Ventajas:**
- Reduce el overfitting que puede ocurrir con un solo 谩rbol de decisi贸n.
- Maneja caracter铆sticas num茅ricas y categ贸ricas.
- Es robusto frente a datos faltantes y valores at铆picos.

#### **Implementaci贸n en Scikit-Learn**

```python
from sklearn.ensemble import RandomForestClassifier

# Crear el modelo
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

# Entrenar el modelo
rf_model.fit(X_train, y_train)

# Hacer predicciones
rf_predictions = rf_model.predict(X_test)
```

### **Referencias adicionales**
-  [Explicaci贸n Simple de Random Forest](https://williamkoehrsen.medium.com/random-forest-simple-explanation-377895a60d2d)

## **13. Ajustar un Modelo a los Datos**

```python
model.fit(X_train, y_train)
```

El m茅todo `.fit()` en Scikit-Learn se utiliza para **entrenar un modelo**. 

Toma como entrada:
- `X_train`: Los datos de entrada (caracter铆sticas o variables independientes).
- `y_train`: Las etiquetas (objetivo o variable dependiente).

Durante este proceso:
1. El modelo aprende los **patrones** o **relaciones** entre `X_train` y `y_train`.
2. Los par谩metros del modelo se ajustan para minimizar el error y mejorar la predicci贸n en futuros datos.

> `.fit()` ajusta el modelo a los datos de entrenamiento para que pueda realizar predicciones en datos nuevos.

## **14. Hacer Predicciones con un Modelo**

Una vez que el modelo ha sido ajustado a los datos mediante `.fit()`, puedes usarlo para hacer predicciones sobre nuevos datos. Esto se logra principalmente utilizando los m茅todos `predict()` y `predict_proba()`.

### **M茅todos de Predicci贸n**

#### **`predict()`**
El m茅todo `predict()` genera predicciones concretas basadas en el modelo ajustado. 

- Para problemas de **clasificaci贸n**, devuelve la **clase m谩s probable**.
- Para problemas de **regresi贸n**, devuelve el **valor predicho** (n煤mero).

```python
y_preds = model.predict(X_test)  # Predicciones sobre datos de prueba
```

#### **`predict_proba()`**
El m茅todo `predict_proba()` genera las probabilidades de pertenencia a cada clase en problemas de **clasificaci贸n**.

- til si quieres entender la confianza del modelo en su predicci贸n.
- Devuelve una matriz donde cada fila corresponde a una instancia y cada columna a la probabilidad de una clase.

```python
y_proba = model.predict_proba(X_test)
```

Ejemplo de salida para una clasificaci贸n binaria:
```python
array([[0.1, 0.9],  # Probabilidad de clase 0 y clase 1
       [0.8, 0.2]])
```

### **Evaluar Predicciones**

Existen varias formas de comparar las predicciones del modelo con las etiquetas verdaderas para evaluar su desempe帽o:

1. **Comparaci贸n directa**  
   Compara las predicciones con las etiquetas verdaderas utilizando operadores l贸gicos.
   ```python
   np.mean(y_preds == y_test)
   ```

2. **M茅todo `.score()` del modelo**  
   Muchos modelos de Scikit-Learn tienen un m茅todo `.score()` que calcula una m茅trica de desempe帽o est谩ndar (por ejemplo, precisi贸n para clasificaci贸n o R虏 para regresi贸n).
   ```python
   model.score(X_test, y_test)
   ```

3. **M茅tricas espec铆ficas con Scikit-Learn**  
   Usa funciones del m贸dulo `metrics` para calcular m茅tricas de evaluaci贸n detalladas.
   ```python
   from sklearn.metrics import accuracy_score
   accuracy_score(y_test, y_preds)
   ```

### **Ejemplo Completo**

```python
# Hacer predicciones
y_preds = model.predict(X_test)

# Calcular precisi贸n directamente
accuracy = np.mean(y_preds == y_test)
print(f"Accuracy (manual): {accuracy}")

# Calcular precisi贸n con .score()
model_accuracy = model.score(X_test, y_test)
print(f"Accuracy (model score): {model_accuracy}")

# Calcular precisi贸n con una m茅trica espec铆fica
from sklearn.metrics import accuracy_score
accuracy_metric = accuracy_score(y_test, y_preds)
print(f"Accuracy (accuracy_score): {accuracy_metric}")
```

> **Nota:** Aunque estas tres formas pueden producir resultados similares, usar funciones espec铆ficas de `metrics` como `accuracy_score` es m谩s flexible para escenarios complejos, como calcular m煤ltiples m茅tricas a la vez.

## **15. Evaluaci贸n de Modelos de Machine Learning**

La evaluaci贸n de modelos de machine learning depende del tipo de problema: clasificaci贸n o regresi贸n. A continuaci贸n, se explican las m茅tricas m谩s comunes y c贸mo utilizarlas de forma pr谩ctica.

### **Clasificaci贸n**

1. **Cross-Validation**  
   Divide los datos en m煤ltiples partes para entrenar y probar el modelo varias veces, asegurando una evaluaci贸n m谩s robusta y menos dependiente de una sola divisi贸n de datos.
   ```python
   from sklearn.model_selection import cross_val_score
   scores = cross_val_score(model, X, y, cv=5)  # 5 divisiones
   print("Mean Cross-Validation Score:", scores.mean())
   ```

   <img src="../assets/section-7/grid_search_cross_validation.png" alt="Validaci贸n cruzada" width="400" style="padding:24px; margin: 24px auto; background: white;">

2. **Accuracy**  
   Porcentaje de predicciones correctas entre el total de predicciones.
   ```python
   from sklearn.metrics import accuracy_score
   accuracy = accuracy_score(y_test, y_preds)
   print("Accuracy:", accuracy)
   ```

3. **ROC Curve**  
   Muestra la relaci贸n entre la tasa de verdaderos positivos y la tasa de falsos positivos. til para evaluar modelos binarios.
   ```python
   from sklearn.metrics import roc_curve
   fpr, tpr, thresholds = roc_curve(y_test, y_proba[:, 1])
   plt.plot(fpr, tpr)
   ```

   <img src="../assets/section-7/interpreting-the-ROC-curve.webp" alt="Interpretaci贸n de la curva ROC" width="500" style="margin: 24px auto; background: white;">

4. **ROC Curve + AUC (rea Bajo la Curva)**  
   Resume el desempe帽o del modelo en un solo valor (AUC). Cuanto m谩s cerca de 1, mejor.
   ```python
   from sklearn.metrics import roc_auc_score
   auc = roc_auc_score(y_test, y_proba[:, 1])
   print("AUC:", auc)
   ```

   <img src="../assets/section-7/auc.png" alt="rea bajo la curva" width="500" style="margin: 24px auto; background: white;">

5. **Matriz de Confusi贸n**  
   Tabla que muestra las predicciones correctas e incorrectas para cada clase.
   ```python
   from sklearn.metrics import confusion_matrix
   cm = confusion_matrix(y_test, y_preds)
   print(cm)
   ```

6. **Classification Report**  
   Resumen detallado de m茅tricas como precisi贸n, recall y F1-score.
   ```python
   from sklearn.metrics import classification_report
   report = classification_report(y_test, y_preds)
   print(report)
   ```

---

### **Regresi贸n**

1. **R虏 Score**  
   Indica qu茅 porcentaje de la variaci贸n en los datos depende de las caracter铆sticas del modelo. El mejor valor posible es 1.0.
   ```python
   from sklearn.metrics import r2_score
   r2 = r2_score(y_test, y_preds)
   print("R虏 Score:", r2)
   ```

2. **Mean Absolute Error (MAE)**  
   Promedio de las diferencias absolutas entre valores predichos y reales. Mide el error en las mismas unidades que la variable dependiente.
   ```python
   from sklearn.metrics import mean_absolute_error
   mae = mean_absolute_error(y_test, y_preds)
   print("MAE:", mae)
   ```

3. **Mean Squared Error (MSE)**  
   Promedio de los errores al cuadrado, penalizando m谩s los errores grandes.
   ```python
   from sklearn.metrics import mean_squared_error
   mse = mean_squared_error(y_test, y_preds)
   print("MSE:", mse)
   ```

---

### **Consejo Pr谩ctico**
- **Clasificaci贸n:** Usa `accuracy_score` como m茅trica inicial y complementa con `classification_report` para analizar m谩s detalles. La `roc_auc_score` es ideal si tienes probabilidades.
- **Regresi贸n:** Comienza con `r2_score` para evaluar el ajuste general del modelo y complementa con `mae` o `mse` dependiendo de si los errores grandes son cr铆ticos o no.

-  [Metrics and scoring: quantifying the quality of predictions - Scikit-Learn](https://scikit-learn.org/stable/modules/model_evaluation)

## **16. Mejorar un Modelo de Machine Learning**

- Ajustar hiperpar谩metros con `GridSearchCV`.
- A帽adir m谩s datos o limpiar los existentes.

---

## **17. Guardar y Cargar Modelos**

```python
import joblib
joblib.dump(model, 'model.pkl')
loaded_model = joblib.load('model.pkl')
```

---

## **18. Resumen Completo y Pr谩ctica Final**

Integra todos los pasos para resolver un problema completo de Machine Learning:

1. Limpia y transforma los datos.
2. Divide los datos.
3. Escala caracter铆sticas.
4. Ajusta un modelo.
5. Eval煤a su desempe帽o.
6. Mejora si es necesario.

---

Este archivo est谩 dise帽ado para que sea un recurso pr谩ctico y 煤til a medida que avances en tu aprendizaje con Scikit-learn.
