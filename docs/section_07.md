# **Scikit-Learn**

[Scikit-learn](https://scikit-learn.org/stable/user_guide.html) es una de las bibliotecas m√°s populares de Python para Machine Learning. Ofrece herramientas simples y eficientes para el an√°lisis de datos y modelado predictivo. Compatible con NumPy, pandas y matplotlib, es ideal para **construir y evaluar modelos de Machine Learning**.

---

## **√çndice**

1. [¬øQu√© es Machine Learning?](#1-qu√©-es-machine-learning)
2. [¬øQu√© es Scikit-Learn?](#2-qu√©-es-scikit-learn)
3. [Workflow en Scikit-Learn](#3-workflow-en-scikit-learn)
4. [Debugging Warnings en Jupyter](#4-debugging-warnings-en-jupyter)
5. [Divisi√≥n de Datos (Splitting Data)](#5-divisi√≥n-de-datos-splitting-data)
6. [Limpieza y Transformaci√≥n de Datos](#6-limpieza-y-transformaci√≥n-de-datos-clean-transform-reduce)
7. [Convertir Datos en N√∫meros](#7-convertir-datos-en-n√∫meros)
8. [Manejo de Valores Faltantes](#8-manejo-de-valores-faltantes)
9. [Escalado de Caracter√≠sticas (Feature Scaling)](#9-escalado-de-caracter√≠sticas-feature-scaling)
10. [Elegir el Modelo Correcto](#10-elegir-el-modeloestimador-adecuado)
11. [√Årboles de Decisi√≥n (Decision Trees)](#11-√°rboles-de-decisi√≥n)
12. [Modelos de Ensamblaje](#12-modelos-de-ensamblaje)
13. [Ajustar un Modelo a los Datos](#13-ajustar-un-modelo-a-los-datos)
14. [Hacer Predicciones con un Modelo](#14-predicciones-con-un-modelo)
15. [Evaluaci√≥n de Modelos de Machine Learning](#15-evaluaci√≥n-de-modelos-de-machine-learning)
16. [Mejorar un Modelo de Machine Learning](#16-mejorar-un-modelo-de-machine-learning)
17. [Guardar y Cargar Modelos](#17-guardar-y-cargar-modelos)

> [!NOTE] > **¬øC√≥mo obtener ayuda?**
>
> - **Experimenta:** Usa lo que sabes y prueba. Aprender haciendo es clave en ML.
> - **SHIFT + TAB:** Usa esta funci√≥n en Jupyter para obtener informaci√≥n sobre una funci√≥n o m√©todo.
> - **Busca online:** Investiga en la documentaci√≥n de [Scikit-Learn](<(https://scikit-learn.org/stable/user_guide.html)>) o en Stack Overflow.
> - **Pregunta:** Si te atascas, pregunta en foros o comunidades de Machine Learning.

---

## **1. ¬øQu√© es Machine Learning?**

Machine Learning (ML) es una rama de la inteligencia artificial que permite a las m√°quinas **aprender patrones de datos sin ser expl√≠citamente programadas.**

- **Tipos de ML:**
  - **Supervisado:** Entrenado con datos etiquetados (ej. predicci√≥n de precios).
  - **No supervisado:** Identifica patrones en datos sin etiquetas (ej. clustering).
  - **Aprendizaje por refuerzo:** Aprende interactuando con el entorno para maximizar recompensas.

<img src="../assets/section-7/machine-learning.webp" alt="Qu√© es machine learning" width="400" style="padding:24px; margin: 24px auto; background: white;">

## **2. ¬øQu√© es Scikit-Learn?**

**Scikit-Learn**, com√∫nmente llamado `sklearn`, es una biblioteca de c√≥digo abierto de Python para Machine Learning.

Est√° construido sobre:

- **NumPy:** Biblioteca de Python para c√°lculos num√©ricos.
- **Matplotlib:** Biblioteca para visualizaci√≥n de datos.

Ofrece herramientas para realizar todas las etapas principales de un proyecto de Machine Learning, desde la preparaci√≥n de datos hasta la construcci√≥n y evaluaci√≥n de modelos.

### ¬øPor qu√© usar Scikit-Learn?

El objetivo principal del Machine Learning es **encontrar patrones en los datos** y usar esos patrones para hacer **predicciones**.

Algunos tipos comunes de problemas de Machine Learning incluyen:

- **Clasificaci√≥n:** Predecir una categor√≠a (ej. si un email es spam o no).
- **Regresi√≥n:** Predecir un n√∫mero (ej. precio de casas).
- **Clustering:** Agrupar elementos similares sin etiquetas previas.

Para cualquier problema, las etapas son similares:

1. Dividir los datos en conjuntos de entrenamiento y prueba.
2. Elegir un modelo.
3. Ajustar el modelo a los datos.
4. Evaluar el modelo para ver si ha aprendido algo.

Scikit-Learn ofrece implementaciones en Python para realizar todas estas tareas, evitando la necesidad de construirlas desde cero.

## **3. Workflow en Scikit-Learn**

1. **Obtener y preparar los datos**
2. **Dividir los datos**
   - en caracter√≠sticas (`X`) y etiquetas (`Y`)
   - en conjuntos de entrenamiento y prueba
3. **Elegir un modelo y sus hiperpar√°metros**
   - Clasificaci√≥n : `RandomForestClassifier`, `LogisticRegression`, `SVC`.
   - Regresi√≥n: `LinearRegression`, `RandomRegressor`.
4. **Ajustar el modelo** a los datos de entrenamiento
5. **Hacer predicciones**: predice etiquetas en datos no vistos
6. **Evaluar el modelo**
   - Clasificaci√≥n: Usa m√©tricas como precisi√≥n, matriz de confusi√≥n, etc.
   - Regresi√≥n: Usa m√©tricas como `r2_score`, `mean_squared_error`.
7. **Experimentar y mejorar** el modelo si es necesario
   - Ajusta los hiperpar√°metros con `GridSerachCV`o prueba modelos m√°s avanzados.
   - Experimenta con diferentes t√©cnicas de preprocesamiento.
8. **Guardar y cargar el modelo**

```python
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error

# Ejemplo simple de workflow
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42) # Dividir los datos
model = LinearRegression() # Modelo elegido
model.fit(X_train, y_train) # Ajustar el modelo
predictions = model.predict(X_test) # Hacer predicciones
error = mean_absolute_error(y_test, predictions) # Evaluar el modelo
```

## **4. Debugging Warnings en Jupyter**

Mientras trabajas en Jupyter Notebook, puedes encontrarte con **mensajes de advertencia** que te alertan sobre **posibles problemas o cambios futuros** en las bibliotecas que utilizas. Estos mensajes son √∫tiles para mejorar tu c√≥digo, pero a veces pueden ser molestos si est√°s experimentando o trabajando con c√≥digo heredado.

### **Tipos comunes de advertencias**

1. **`FutureWarning`:** Indica que algo en tu c√≥digo ser√° obsoleto en una versi√≥n futura.
2. **`DeprecationWarning`:** Similar a `FutureWarning`, pero se usa para elementos que ya est√°n obsoletos.
3. **`UserWarning`:** Mensajes de advertencia personalizados o relacionados con configuraciones espec√≠ficas.

### **C√≥mo manejar advertencias en Scikit-Learn**

1. **Lee el mensaje de advertencia completo:**

   - Identifica qu√© est√° causando la advertencia. Por ejemplo:
     ```
     FutureWarning: The parameter 'normalize' in function 'LinearRegression' is deprecated and will be removed in version 1.2. Please use 'StandardScaler' instead.
     ```
   - Esto sugiere reemplazar `normalize=True` por el uso de `StandardScaler`.

2. **Consulta la documentaci√≥n oficial:**

   - La advertencia suele mencionar una soluci√≥n recomendada. Busca el t√©rmino o funci√≥n en la [documentaci√≥n oficial de Scikit-Learn](https://scikit-learn.org/stable/documentation.html).

3. **Actualiza tu c√≥digo para evitar advertencias futuras:**

   - Adapta tu c√≥digo siguiendo las recomendaciones.
   - Ejemplo de correcci√≥n:

     ```python
     # Antes (genera FutureWarning)
     from sklearn.linear_model import LinearRegression
     model = LinearRegression(normalize=True)

     # Despu√©s (soluci√≥n recomendada)
     from sklearn.pipeline import make_pipeline
     from sklearn.preprocessing import StandardScaler
     model = make_pipeline(StandardScaler(), LinearRegression())
     ```

4. **Ignorar advertencias temporalmente:**

   - Si necesitas ignorar advertencias durante el desarrollo, puedes usar:
     ```python
     import warnings
     warnings.filterwarnings("ignore", category=FutureWarning)
     ```
     Esto suprime **solo** los mensajes de `FutureWarning`.

5. **Habilitar advertencias para depuraci√≥n:**
   - Si necesitas volver a habilitar las advertencias:
     ```python
     warnings.filterwarnings("default")
     ```

#### **Ejemplo pr√°ctico para `FutureWarning` en Scikit-Learn**

Si est√°s trabajando con una versi√≥n m√°s antigua de Scikit-Learn y ves un `FutureWarning`, actualiza la biblioteca para evitar el problema:

```bash
pip install -U scikit-learn
```

### **Actualizar Scikit-Learn con conda**

Si est√°s usando **conda** como gestor de entornos, puedes actualizar **Scikit-Learn** y otras bibliotecas directamente desde la terminal. Aqu√≠ tienes los pasos para hacerlo:

1. **Activar el entorno Conda:**
   Primero aseg√∫rate de activar el entorno en el que deseas actualizar Scikit-Learn:

   ```bash
   conda activate nombre_del_entorno
   ```

2. **Actualizar Scikit-Learn:**
   Ejecuta el siguiente comando para actualizar Scikit-Learn a la √∫ltima versi√≥n disponible en los canales de Conda:

   ```bash
   conda update scikit-learn
   ```

3. **Confirmar la instalaci√≥n:**
   Si Conda encuentra una versi√≥n m√°s reciente, pedir√° confirmaci√≥n para actualizar. Escribe `y` y presiona **Enter** para proceder.

#### **Actualizar Scikit-Learn a una versi√≥n espec√≠fica:**

Si necesitas una versi√≥n espec√≠fica de Scikit-Learn, usa:

```bash
conda install scikit-learn=1.2.0
```

(Reemplaza `1.2.0` con la versi√≥n que necesites.)

#### **Actualizar todo el entorno Conda**

Si prefieres actualizar todas las bibliotecas de tu entorno al mismo tiempo, puedes usar:

```bash
conda update --all
```

#### **Verificar la versi√≥n instalada**

Despu√©s de actualizar, verifica que tienes la versi√≥n correcta:

```python
import sklearn
print(sklearn.__version__)
```

> [!Note] > **Notas importantes**
>
> - Si no encuentras la versi√≥n m√°s reciente de Scikit-Learn en los canales predeterminados de Conda, puedes intentar instalarla desde el canal `conda-forge`:
>
> ```bash
> conda install -c conda-forge scikit-learn
> ```
>
> - Actualizar Scikit-Learn puede requerir actualizar otras bibliotecas como **NumPy** y **SciPy**, ya que Scikit-Learn depende de ellas. Conda manejar√° estas dependencias autom√°ticamente.
> - Si no puedes actualizar, puedes ignorar las advertencias de forma temporal o adaptarte a las nuevas recomendaciones que aparecen en la advertencia.

#### **Buenas pr√°cticas**

- Usa `warnings.filterwarnings("ignore")` solo como √∫ltima opci√≥n o mientras experimentas.
- Actualiza tus bibliotecas regularmente para evitar problemas de compatibilidad.
- Consulta siempre la documentaci√≥n oficial y las notas de la versi√≥n:
  - üîó [Notas de versi√≥n de Scikit-Learn](https://scikit-learn.org/stable/whats_new.html).

## **5. Divisi√≥n de Datos (Splitting Data)**

Un paso crucial en cualquier proyecto de machine learning es dividir los datos en conjuntos de entrenamiento y prueba para evaluar c√≥mo se comporta el modelo con datos no vistos.

La funci√≥n `train_test_split` de Scikit-Learn divide los datos en dos o m√°s conjuntos:

- **Entrenamiento (`train`):** Datos que el modelo utiliza para aprender patrones.
- **Prueba (`test`):** Datos reservados para evaluar el modelo despu√©s del entrenamiento.

Ejemplo b√°sico:

```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,  # Proporci√≥n del conjunto de prueba (20%)
    random_state=42 # Fijar semilla para resultados reproducibles
)
```

- **`test_size`:** Define el porcentaje de datos asignados al conjunto de prueba.
- **`random_state`:** Asegura que los datos se dividan de la misma forma en cada ejecuci√≥n, √∫til para experimentos reproducibles.

## **6. Limpieza y Transformaci√≥n de Datos (Clean, Transform, Reduce)**

#### **Limpieza (`Clean`):**

- Elimina valores faltantes o err√≥neos para evitar que distorsionen los resultados del modelo.
- Por ejemplo, puedes usar Pandas para eliminar filas con valores nulos:
  ```python
  X.dropna(inplace=True)
  ```

#### **Transformaci√≥n (`Transform`):**

- Convierte los datos a formatos adecuados, como escalar valores num√©ricos o codificar variables categ√≥ricas.
- Ejemplo: Escalar caracter√≠sticas num√©ricas usando `StandardScaler`:
  ```python
  from sklearn.preprocessing import StandardScaler
  scaler = StandardScaler()
  X_scaled = scaler.fit_transform(X)
  ```

#### **Reducci√≥n (`Reduce`):**

- Simplifica los datos, por ejemplo, reduciendo la dimensionalidad con PCA si el conjunto de datos tiene muchas caracter√≠sticas.
- Ejemplo:
  ```python
  from sklearn.decomposition import PCA
  pca = PCA(n_components=2)
  X_reduced = pca.fit_transform(X)
  ```

> [!NOTE] > **Nota Pr√°ctica**
>
> - Una divisi√≥n mal realizada puede generar un modelo que no generalice bien.
> - Si los datos son muy peque√±os, considera **validaci√≥n cruzada** en lugar de dividir en `train/test`.
> - Siempre inspecciona los datos despu√©s de dividirlos para garantizar que los conjuntos sean representativos:
>
> ```python
> print(X_train.shape, X_test.shape)
> print(y_train.value_counts(), y_test.value_counts())
> ```

## **7. Convertir Datos en N√∫meros**

Los algoritmos de machine learning suelen trabajar mejor con datos num√©ricos. Sin embargo, en muchos casos, los datos contienen **variables categ√≥ricas** (como colores, pa√≠ses, tipos de productos, etc.). Para convertir estos datos categ√≥ricos en n√∫meros, Scikit-Learn proporciona herramientas como `LabelEncoder` y `OneHotEncoder`.

### **1. `LabelEncoder`**

El `LabelEncoder` asigna un n√∫mero √∫nico a cada categor√≠a de una columna. Este m√©todo es √∫til cuando las categor√≠as tienen un **orden l√≥gico**, como "bajo", "medio", "alto".

Ejemplo:

```python
from sklearn.preprocessing import LabelEncoder

data = pd.DataFrame({"color": ["red", "blue", "green", "blue", "red"]})

label_encoder = LabelEncoder()
data["color_encoded"] = label_encoder.fit_transform(data["color"])
print(data)
```

**Salida:**

```plaintext
   color  color_encoded
0    red              2
1   blue              0
2  green              1
3   blue              0
4    red              2
```

- **Ventajas:** Simple y directo.
- **Desventajas:** Puede inducir relaciones ordinales incorrectas entre las categor√≠as si no hay un orden l√≥gico.

### **2. `OneHotEncoder`**

El `OneHotEncoder` crea columnas binarias (0 o 1) para cada categor√≠a, evitando que el modelo asuma relaciones ordinales entre categor√≠as.

<img src="../assets/section-7/one_hot_encoding.png" alt="One Hot Encoding" width="600" style="margin: 24px auto; background: white;">

Ejemplo:

```python
from sklearn.preprocessing import OneHotEncoder

data = pd.DataFrame({"color": ["red", "blue", "green", "blue", "red"]})

one_hot_encoder = OneHotEncoder()
encoded = one_hot_encoder.fit_transform(data[["color"]])
print(encoded.toarray())  # Convertir a matriz NumPy para ver los resultados
```

**Salida:**

```plaintext
[[0. 0. 1.]
 [1. 0. 0.]
 [0. 1. 0.]
 [1. 0. 0.]
 [0. 0. 1.]]
```

- Las columnas representan categor√≠as en orden alfab√©tico: `["blue", "green", "red"]`.
- **Ventajas:** Evita relaciones ordinales falsas.
- **Desventajas:** Incrementa el tama√±o del dataset si hay muchas categor√≠as.

> [!NOTE]
>
> - En una versi√≥n m√°s nueva de Scikit-Learn (0.23+), la clase `OneHotEncoder` puede manejar valores `None` y `NaN`.
> - üîó [Documentaci√≥n OneHotEncoder Scikit-Learn](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)

### **3. Usar `ColumnTransformer` con `OneHotEncoder`**

Si tienes varias columnas categ√≥ricas y num√©ricas en tu dataset, puedes usar `ColumnTransformer` para aplicar transformaciones espec√≠ficas a cada tipo de columna.

Ejemplo pr√°ctico:

```python
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder

data = pd.DataFrame({
    "color": ["red", "blue", "green", "blue", "red"],
    "size": ["S", "M", "L", "M", "S"],
    "price": [10, 20, 15, 25, 30]
})

categorical_features = ["color", "size"]
one_hot_encoder = OneHotEncoder()

transformer = ColumnTransformer(
   transformers=[("one_hot", one_hot_encoder, categorical_features)],
   remainder="passthrough"  # Deja las columnas no especificadas sin cambios
)

transformed_data = transformer.fit_transform(data)
print(transformed_data)
```

**Salida:**

```plaintext
[[0. 0. 1. 1. 0. 0. 10.]
 [1. 0. 0. 0. 1. 0. 20.]
 [0. 1. 0. 0. 0. 1. 15.]
 [1. 0. 0. 0. 1. 0. 25.]
 [0. 0. 1. 1. 0. 0. 30.]]
```

### **Tips para elegir el m√©todo adecuado:**

1. Usa `LabelEncoder` si tus categor√≠as tienen un **orden l√≥gico** o si son simples y est√°n contenidas en una √∫nica columna.
2. Usa `OneHotEncoder` si quieres evitar relaciones ordinales falsas entre categor√≠as.
3. Si trabajas con datasets m√°s complejos (mixtos con columnas categ√≥ricas y num√©ricas), utiliza `ColumnTransformer` para combinar transformaciones.

## **8. Manejo de Valores Faltantes**

### Con pandas:

```python
df["column"] = df["column"].fillna(value)
```

### Con Scikit-Learn:

```python
from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy="mean")
imputed = imputer.fit_transform(df)
```

## **9. Escalado de Caracter√≠sticas (Feature Scaling)**

Una vez que tus datos est√©n en formato num√©rico, probablemente querr√°s aplicarles una transformaci√≥n adicional: **escalado de caracter√≠sticas (Feature Scaling)**. Esto significa asegurarte de que **todos los datos num√©ricos est√©n en la misma escala**.

**¬øPor qu√© es importante?**

Imagina que est√°s tratando de predecir el precio de venta de coches y el kilometraje var√≠a entre 6,000 y 345,000, mientras que el costo promedio de reparaciones anteriores var√≠a entre 100 y 1,700. Un algoritmo de aprendizaje autom√°tico podr√≠a tener dificultades para encontrar patrones en estas variables con rangos tan diferentes.

Para solucionar esto, existen dos tipos principales de escalado de caracter√≠sticas:

1. **Normalizaci√≥n (`MinMaxScaler`):**

   - Este m√©todo reescala todos los valores num√©ricos para que est√©n entre 0 y 1.
   - El valor m√°s bajo estar√° cerca de 0, y el m√°s alto estar√° cerca de 1.
   - [Scikit-Learn proporciona la clase `MinMaxScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) para realizar esta operaci√≥n.

2. **Estandarizaci√≥n (`StandardScaler`):**

   - Este m√©todo resta la media de cada caracter√≠stica, de modo que los valores resultantes tengan una media de 0.
   - Luego escala las caracter√≠sticas a varianza unitaria (dividiendo por la desviaci√≥n est√°ndar).
   - [Scikit-Learn proporciona la clase `StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html) para esta tarea.

   ```python
   from sklearn.preprocessing import StandardScaler
   scaler = StandardScaler()
   scaled_data = scaler.fit_transform(data)
   ```

> [!NOTE] **Notas importantes:**
>
> - El **escalado de caracter√≠sticas generalmente no se aplica a la variable objetivo** (la que intentas predecir).
> - El **escalado de caracter√≠sticas no suele ser necesario en modelos basados en √°rboles** (por ejemplo, Random Forest), ya que estos pueden manejar caracter√≠sticas con diferentes escalas.

**üìñ Lectura adicional**

- **[Feature Scaling - why is it required?](https://rahul-saini.medium.com/feature-scaling-why-it-is-required-8a93df1af310)** por Rahul Saini.
- **[Feature Scaling with Scikit-Learn](https://benalexkeen.com/feature-scaling-with-scikit-learn/)** por Ben Alex Keen.
- **[Feature Scaling for Machine Learning: Understanding the Difference Between Normalization vs. Standardization](https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/)** por Aniruddha Bhandari.

## **10. Elegir el modelo/estimador adecuado**

A menudo, la parte m√°s dif√≠cil de resolver un problema de aprendizaje autom√°tico puede ser encontrar el estimador adecuado para el trabajo. Diferentes estimadores son m√°s adecuados para distintos tipos de datos y problemas.

Este [diagrama de flujo de Scikit-learn](https://scikit-learn.org/1.5/machine_learning_map.html) est√° dise√±ado como una gu√≠a aproximada para ayudar a los usuarios a abordar problemas en relaci√≥n con qu√© estimadores probar en sus datos. Puedes hacer clic en cualquier estimador del gr√°fico para ver su documentaci√≥n. El emoji üò≠ debe interpretarse como _"si este estimador no logra el resultado deseado, sigue la flecha e intenta con el siguiente"_.

<img src="../assets/section-7/ml_map.svg" alt="Diagrama de un √Årbol de decisi√≥n" width="800" style="padding:24px; margin: 24px auto; background: white;">

## **11. √Årboles de Decisi√≥n**

Un **√Årbol de Decisi√≥n** es un modelo de machine learning que utiliza una estructura jer√°rquica de decisiones para dividir los datos en ramas seg√∫n ciertas reglas condicionales. Se utiliza tanto en problemas de **clasificaci√≥n** como de **regresi√≥n**.

<img src="../assets/section-7/decision-tree.png" alt="Diagrama de un √Årbol de decisi√≥n" width="500" style="padding:24px; margin: 24px auto; background: white;">

### **Caracter√≠sticas principales**

- **F√°cil de interpretar:** La estructura de decisiones permite visualizar c√≥mo el modelo llega a una conclusi√≥n.
- **Capacidad de manejar datos categ√≥ricos y num√©ricos.**
- **Propenso al overfitting:** Sin regularizaci√≥n, los √°rboles de decisi√≥n pueden ajustarse demasiado a los datos de entrenamiento.

### **Implementaci√≥n en Scikit-Learn**

```python
from sklearn.tree import DecisionTreeClassifier

# Crear el modelo
model = DecisionTreeClassifier()

# Entrenar el modelo
model.fit(X_train, y_train)

# Hacer predicciones
predictions = model.predict(X_test)
```

### **Visualizaci√≥n de un √Årbol de Decisi√≥n**

Puedes visualizar el √°rbol utilizando `plot_tree` de Scikit-Learn:

```python
from sklearn.tree import plot_tree

plt.figure(figsize=(12, 8))
plot_tree(model, filled=True, feature_names=X.columns, class_names=["Clase 0", "Clase 1"])
plt.show()
```

## **12. Modelos de Ensamblaje**

Un **Modelo de Ensamblaje** combina m√∫ltiples modelos (como √°rboles de decisi√≥n) para mejorar la precisi√≥n, robustez y generalizaci√≥n.

### **Tipos de Modelos de Ensamblaje**

1. **Bagging (Bootstrap Aggregating):** Entrena varios modelos independientes (como √°rboles de decisi√≥n) en subconjuntos de los datos y combina sus predicciones (e.g., Random Forest).
2. **Boosting:** Entrena modelos secuencialmente, corrigiendo los errores del modelo anterior (e.g., Gradient Boosting, XGBoost).
3. **Stacking:** Combina diferentes tipos de modelos y utiliza otro modelo para aprender de sus predicciones.

### **Random Forest**

Un **Random Forest** es un tipo de modelo de ensamblaje basado en Bagging que combina m√∫ltiples √°rboles de decisi√≥n.

<img src="../assets/section-7/random_forest.png" alt="Random Forest Conceptual Diagram" width="500" style="margin: 16px auto; background: white;">

#### **Ventajas:**

- Reduce el overfitting que puede ocurrir con un solo √°rbol de decisi√≥n.
- Maneja caracter√≠sticas num√©ricas y categ√≥ricas.
- Es robusto frente a datos faltantes y valores at√≠picos.

#### **Implementaci√≥n en Scikit-Learn**

```python
from sklearn.ensemble import RandomForestClassifier

# Crear el modelo
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)

# Entrenar el modelo
rf_model.fit(X_train, y_train)

# Hacer predicciones
rf_predictions = rf_model.predict(X_test)
```

### **Referencias adicionales**

- üîó [Explicaci√≥n Simple de Random Forest](https://williamkoehrsen.medium.com/random-forest-simple-explanation-377895a60d2d)

## **13. Ajustar un Modelo a los Datos**

```python
model.fit(X_train, y_train)
```

El m√©todo `.fit()` en Scikit-Learn se utiliza para **entrenar un modelo**.

Toma como entrada:

- `X_train`: Los datos de entrada (caracter√≠sticas o variables independientes).
- `y_train`: Las etiquetas (objetivo o variable dependiente).

Durante este proceso:

1. El modelo aprende los **patrones** o **relaciones** entre `X_train` y `y_train`.
2. Los par√°metros del modelo se ajustan para minimizar el error y mejorar la predicci√≥n en futuros datos.

> `.fit()` ajusta el modelo a los datos de entrenamiento para que pueda realizar predicciones en datos nuevos.

## **14. Hacer Predicciones con un Modelo**

Una vez que el modelo ha sido ajustado a los datos mediante `.fit()`, puedes usarlo para hacer predicciones sobre nuevos datos. Esto se logra principalmente utilizando los m√©todos `predict()` y `predict_proba()`.

### **M√©todos de Predicci√≥n**

#### **`predict()`**

El m√©todo `predict()` genera predicciones concretas basadas en el modelo ajustado.

- Para problemas de **clasificaci√≥n**, devuelve la **clase m√°s probable**.
- Para problemas de **regresi√≥n**, devuelve el **valor predicho** (n√∫mero).

```python
y_preds = model.predict(X_test)  # Predicciones sobre datos de prueba
```

#### **`predict_proba()`**

El m√©todo `predict_proba()` genera las probabilidades de pertenencia a cada clase en problemas de **clasificaci√≥n**.

- √ötil si quieres entender la confianza del modelo en su predicci√≥n.
- Devuelve una matriz donde cada fila corresponde a una instancia y cada columna a la probabilidad de una clase.

```python
y_proba = model.predict_proba(X_test)
```

Ejemplo de salida para una clasificaci√≥n binaria:

```python
array([[0.1, 0.9],  # Probabilidad de clase 0 y clase 1
       [0.8, 0.2]])
```

### **Evaluar Predicciones**

Existen varias formas de comparar las predicciones del modelo con las etiquetas verdaderas para evaluar su desempe√±o:

1. **Comparaci√≥n directa**  
   Compara las predicciones con las etiquetas verdaderas utilizando operadores l√≥gicos.

   ```python
   np.mean(y_preds == y_test)
   ```

2. **M√©todo `.score()` del modelo**  
   Muchos modelos de Scikit-Learn tienen un m√©todo `.score()` que calcula una m√©trica de desempe√±o est√°ndar (por ejemplo, precisi√≥n para clasificaci√≥n o R¬≤ para regresi√≥n).

   ```python
   model.score(X_test, y_test)
   ```

3. **M√©tricas espec√≠ficas con Scikit-Learn**  
   Usa funciones del m√≥dulo `metrics` para calcular m√©tricas de evaluaci√≥n detalladas.
   ```python
   from sklearn.metrics import accuracy_score
   accuracy_score(y_test, y_preds)
   ```

### **Ejemplo Completo**

```python
# Hacer predicciones
y_preds = model.predict(X_test)

# Calcular precisi√≥n directamente
accuracy = np.mean(y_preds == y_test)
print(f"Accuracy (manual): {accuracy}")

# Calcular precisi√≥n con .score()
model_accuracy = model.score(X_test, y_test)
print(f"Accuracy (model score): {model_accuracy}")

# Calcular precisi√≥n con una m√©trica espec√≠fica
from sklearn.metrics import accuracy_score
accuracy_metric = accuracy_score(y_test, y_preds)
print(f"Accuracy (accuracy_score): {accuracy_metric}")
```

> **Nota:** Aunque estas tres formas pueden producir resultados similares, usar funciones espec√≠ficas de `metrics` como `accuracy_score` es m√°s flexible para escenarios complejos, como calcular m√∫ltiples m√©tricas a la vez.

## **15. Evaluaci√≥n de Modelos de Machine Learning**

Evaluar los resultados de un modelo de machine learning es tan crucial como construirlo. Cada tipo de problema, ya sea de **clasificaci√≥n o regresi√≥n**, requiere m√©tricas de evaluaci√≥n espec√≠ficas que permitan medir el rendimiento del modelo de manera adecuada. A continuaci√≥n, se describen algunas de las m√©tricas m√°s importantes y utilizadas para evaluar modelos en ambos contextos.

### M√©tricas/T√©cnicas de Evaluaci√≥n para Modelos de **Clasificaci√≥n**

#### **Cross-Validation** (Validaci√≥n Cruzada)

Divide los datos en m√∫ltiples partes para entrenar y probar el modelo varias veces, asegurando una evaluaci√≥n m√°s robusta y menos dependiente de una sola divisi√≥n de datos.

```python
from sklearn.model_selection import cross_val_score
scores = cross_val_score(model, X, y, cv=5)  # 5 divisiones
print("Mean Cross-Validation Score:", scores.mean())
```

Divide el conjunto de datos en m√∫ltiples partes, entrena y eval√∫a el modelo en cada una y calcula el rendimiento promedio.

<img src="../assets/section-7/grid_search_cross_validation.png" alt="Validaci√≥n cruzada" width="400" style="padding:24px; margin: 24px auto; background: white;">

> üîó [Corss-validation: evaluating estimator performance (Scikit-Learn)](https://scikit-learn.org/stable/modules/cross_validation.html)

#### **Accuracy** (Exactitud)

Porcentaje de predicciones correctas entre el total de predicciones.

```python
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(y_test, y_preds)
print("Accuracy:", accuracy)
```

Es la proporci√≥n de predicciones correctas del modelo, expresada en forma decimal. Una precisi√≥n perfecta es igual a 1.0.

#### **Precision** (Precisi√≥n)

Indica la proporci√≥n de identificaciones positivas (predicciones de clase 1 del modelo) que fueron realmente correctas. Un modelo sin falsos positivos tiene una precisi√≥n de 1.0.

üîó [`precision_score` Scikit-Learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score)

#### **Recall** (Exhaustividad)

Mide la proporci√≥n de verdaderos positivos que fueron clasificados correctamente. Un modelo sin falsos negativos tiene un recall de 1.0.

```python
from sklearn.metrics import recall_score
recall_score(y_true, y_pred, average='macro')
```

üîó [`recall_score` Scikit-Learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score)

#### **F1 Score**

Combina precisi√≥n y recall en una √∫nica m√©trica. Un modelo perfecto alcanza un F1 score de 1.0.

üîó [`f1_score` Scikit-Learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score)

#### **ROC Curve** (Curva ROC)

Gr√°fico que muestra la relaci√≥n entre la **tasa de verdaderos positivos** y la **tasa de falsos positivos**. √ötil para evaluar modelos binarios.

<img src="../assets/section-7/tpr_fpr.png" alt="Tasa verdaderos positivos y falsos positivos" width="500" style="margin: 24px auto; background: white;">

```python
from sklearn.metrics import roc_curve
fpr, tpr, thresholds = roc_curve(y_test, y_proba[:, 1])
plt.plot(fpr, tpr)
```

<img src="../assets/section-7/interpreting-the-ROC-curve.webp" alt="Interpretaci√≥n de la curva ROC" width="500" style="margin: 24px auto; background: white;">

#### **ROC Curve + AUC (√Årea Bajo la Curva)**

Resume el desempe√±o del modelo en un solo valor (AUC). El AUC representa el √°rea debajo de la curva ROC. Un modelo perfecto tiene un AUC de `1.0`.

- üîó [Receiver operating characteristic - Wikipedia](https://en.wikipedia.org/wiki/Receiver_operating_characteristic)
- üîó [Curva ROC - Wikipedia](https://es.wikipedia.org/wiki/Curva_ROC)

```python
from sklearn.metrics import roc_auc_score
auc = roc_auc_score(y_test, y_proba[:, 1])
print("AUC:", auc)
```

Las **curvas ROC** y las **m√©tricas AUC** son m√©tricas de evaluaci√≥n para modelos de clasificaci√≥n binaria (un modelo que predice una cosa u otra, como enfermedad card√≠aca o no).

La **curva ROC** compara la tasa de verdaderos positivos (tpr) versus la tasa de falsos positivos (fpr) en diferentes umbrales de clasificaci√≥n.

- Verdadero positivo = el modelo predice 1 cuando la verdad es 1
- Falso positivo = el modelo predice 1 cuando la verdad es 0
- Verdadero negativo = el modelo predice 0 cuando la verdad es 0
- Falso negativo = el modelo predice 0 cuando la verdad es 1

La **[m√©trica AUC](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)** te dice qu√© tan bien est√° tu modelo al elegir entre clases (por ejemplo, qu√© tan bien est√° al decidir si alguien tiene enfermedad card√≠aca o no). Un modelo perfecto obtendr√° una puntuaci√≥n AUC de `1`.

<img src="../assets/section-7/auc.png" alt="√Årea bajo la curva" width="500" style="margin: 24px auto; background: white;">

> [!NOTE] > **Recursos para m√°s informaci√≥n sobre estas m√©tricas:**
>
> - [ROC and AUC, Clearly Explained!](https://www.youtube.com/watch?v=4jRBRDbJemM) por StatQuest
> - [Documentaci√≥n ROC en Scikit-Learn](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html) (contiene ejemplos de c√≥digo)
> - [C√≥mo se calculan la curva ROC y AUC](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc?hl=es-419) por el equipo de Machine Learning de Google.

#### **Matriz de Confusi√≥n**

Tabla que muestra las predicciones correctas e incorrectas para cada clase.

```python
from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test, y_preds)
print(cm)
```

Tambi√©n es posible visualizar una matriz de confusi√≥n usando `pd.crosstab()`:

```python
pd.crosstab(y_test,
            y_preds,
            rownames=["Actual Label"],
            colnames=["Predicted Label"])
```

Compara los valores predichos con los valores reales en forma tabular. Si el modelo es 100% preciso, todos los valores estar√°n en la diagonal de la matriz.

<img src="../assets/section-7/matrix.png" alt="Anatom√≠a matriz de confusi√≥n" width="500" style="margin: 24px auto; background: white;">

> üîó [Confusion Matrix - Wikipedia](https://en.wikipedia.org/wiki/Confusion_matrix)
> üîó [Simple guide to Confusion Matrix terminology - dataschool](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/)

#### **Classification Report**

[Scikit-learn ofrece la funci√≥n `classification_report()`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html), que muestra un resumen detallado de m√©tricas clave como precisi√≥n, recall y F1 score.

```python
from sklearn.metrics import classification_report
report = classification_report(y_test, y_preds)
print(report)
```

---

> **¬øQu√© m√©trica de clasificaci√≥n usar?** > **Accuracy:** Ideal si las clases est√°n equilibradas (por ejemplo, igual cantidad de muestras con etiquetas 0 y 1).
> **Precision y Recall:** √ötiles cuando las clases est√°n desbalanceadas.
>
> - Si los falsos positivos son m√°s perjudiciales que los falsos negativos, prioriza la **precisi√≥n**.
> - Si los falsos negativos son m√°s perjudiciales que los falsos positivos, prioriza el **recall**.
>   **F1 Score:** Buena combinaci√≥n entre precisi√≥n y recall.
>   **Matriz de confusi√≥n:** Siempre es √∫til para visualizar c√≥mo funciona el modelo.

---

### M√©tricas/T√©cnicas de Evaluaci√≥n para Modelos de **Regresi√≥n**

#### **R¬≤ Score** (Coeficiente de Determinaci√≥n)

Indica qu√© porcentaje de la variaci√≥n en los datos depende de las caracter√≠sticas del modelo. El mejor valor posible es 1.0.

```python
from sklearn.metrics import r2_score
r2 = r2_score(y_test, y_preds)
print("R¬≤ Score:", r2)
```

Compara las predicciones del modelo con la media de los valores reales. Los valores pueden variar desde -‚àû (modelo muy malo) hasta 1 (modelo perfecto). Por ejemplo:

- Un modelo que solo predice la media de los valores tiene un R¬≤ de 0.
- Un modelo que predice perfectamente los valores tiene un R¬≤ de 1.

> üîó [`r2_score` Scikit-Learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html)

#### **Mean Absolute Error (MAE)**

Promedio de las diferencias absolutas entre valores predichos y reales. Proporciona una idea de cu√°nto se equivocaron las predicciones en promedio. Mide el error en las mismas unidades que la variable dependiente.

```python
from sklearn.metrics import mean_absolute_error
mae = mean_absolute_error(y_test, y_preds)
print("MAE:", mae)
```

> üîó [`mean_absolute_error` Scikit-Learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html)

#### **Mean Squared Error (MSE)**

Promedio de los errores al cuadrado, penalizando m√°s los errores grandes.

```python
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(y_test, y_preds)
print("MSE:", mse)
```

Promedio de las diferencias cuadradas entre las predicciones y los valores reales. Al elevar las diferencias al cuadrado:

- Se eliminan los valores negativos.
- Se amplifican los errores grandes.

> üîó [`mean_squared_error` Scikit-Learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)

---

> _¬øQu√© m√©trica de regresi√≥n usar?_ > **R¬≤:** Similar a la precisi√≥n en clasificaci√≥n. Da una indicaci√≥n general de qu√© tan bien funciona el modelo (valores cercanos a 1.0 son mejores), pero no indica cu√°nto se equivoca en promedio.
> **MAE:** Muestra cu√°n lejos est√°n en promedio las predicciones del modelo de los valores reales.
> **MSE:** √ötil si deseas penalizar m√°s los errores grandes.
>
> - **Prioriza MAE:** Si un error de $10,000 es el doble de malo que un error de $5,000.
> - **Prioriza MSE:** Si un error de $10,000 es m√°s de dos veces peor que un error de $5,000.

---

> [!NOTE] >**Consejo Pr√°ctico**
>
> - **Clasificaci√≥n:** Usa `accuracy_score` como m√©trica inicial y complementa con `classification_report` para analizar m√°s detalles. La `roc_auc_score` es ideal si tienes probabilidades.
> - **Regresi√≥n:** Comienza con `r2_score` para evaluar el ajuste general del modelo y complementa con `mae` o `mse` dependiendo de si los errores grandes son cr√≠ticos o no.

### Recursos adicionales

- üîó [Metrics and scoring: quantifying the quality of predictions - Scikit-Learn](https://scikit-learn.org/stable/modules/model_evaluation)
- üîó [Beyond Accuracy: Precision and Recall](https://towardsdatascience.com/beyond-accuracy-precision-and-recall-3da06bea9f6c)
- üîó [Stack Overflow answer describing MSE (mean squared error) and RSME (root mean squared error)](https://stackoverflow.com/questions/17197492/is-there-a-library-function-for-root-mean-square-error-rmse-in-python/37861832#37861832)

## **16. Mejorar un Modelo de Machine Learning**

- Ajustar hiperpar√°metros con `GridSearchCV`.
- A√±adir m√°s datos o limpiar los existentes.

## **17. Guardar y Cargar Modelos**

```python
import joblib
joblib.dump(model, 'model.pkl')
loaded_model = joblib.load('model.pkl')
```

---
