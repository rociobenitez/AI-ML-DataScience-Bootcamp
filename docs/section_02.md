# Framework de Machine Learning

Esta secci√≥n se centra en la creaci√≥n de un framework claro para abordar proyectos de Machine Learning y en el proceso t√©cnico del modelado de datos. La estructura presentada aqu√≠ servir√° como referencia pr√°ctica y organizada para implementar estos conceptos en proyectos futuros.

---

## **√çndice**

1. [Framework en 6 Pasos para Proyectos de ML](#framework-en-6-pasos-para-proyectos-de-ml)
2. [Paso 1: Definici√≥n del Problema](#paso-1-definici√≥n-del-problema)
3. [Paso 2: Datos](#paso-2-datos)
4. [Paso 3: Evaluaci√≥n](#paso-3-evaluaci√≥n)
   - [M√©tricas en Regresi√≥n](#m√©tricas-en-regresi√≥n)
   - [M√©tricas en Clasificaci√≥n](#m√©tricas-en-clasificaci√≥n)
   - [M√©tricas en Problemas de Recomendaci√≥n](#m√©tricas-en-problemas-de-recomendaci√≥n)
5. [Paso 4: Features o Caracter√≠sticas](#paso-4-features-o-caracter√≠sticas)
6. [Paso 5: Modelado](#paso-5-modelado)
   - [Divisi√≥n de datos (splitting)](#1-divisi√≥n-de-datos-splitting)
   - [Elecci√≥n del Modelo](#2-elecci√≥n-del-modelo)
   - [Mejora y Ajuste del Modelo](#3-mejora-y-ajuste-del-modelo)
   - [Comparaci√≥n de Modelos](#4-comparaci√≥n-de-modelos)
   - [Overfitting vs Underfitting](#overfitting-vs-underfitting)
7. [Paso 6: Experimentaci√≥n y Mejora](#paso-6-experimentaci√≥n-y-mejora)
8. [Herramientas y Recursos Clave](#herramientas-y-recursos-clave)

---

## **Framework en 6 Pasos para Proyectos de ML**

Este framework proporciona una gu√≠a clara y organizada para abordar cualquier proyecto de Machine Learning, desde la definici√≥n inicial hasta la experimentaci√≥n y mejora continua. Se puede utilizar como referencia para garantizar que cada paso est√© alineado con los objetivos del problema y los datos disponibles.

1. **Definici√≥n del Problema:**

   - ¬øQu√© problema pr√°ctico o empresarial estamos tratando de resolver?
   - ¬øC√≥mo puede reformularse como un problema de Machine Learning?
   - ¬øSupervisado o no supervisado? ¬øProblema de clasificaci√≥n o de regresi√≥n?
   - Ejemplo: "Queremos predecir el abandono de clientes" ‚Üí "¬øPodemos usar datos hist√≥ricos para identificar patrones de abandono?"

2. **Datos:**

   - ¬øQu√© datos tenemos disponibles? ¬øSon suficientes para resolver el problema?
   - ¬øC√≥mo se relacionan estos datos con la definici√≥n del problema?
   - Tipos de datos:
     - **Estructurados o no estructurados:** Tablas vs. im√°genes, texto, audio.
     - **Est√°ticos o en flujo:** Datos almacenados vs. datos en tiempo real.

3. **Evaluaci√≥n:**

   - ¬øQu√© m√©trica definir√° el √©xito del modelo?
   - Ejemplo: Una precisi√≥n del 95% puede ser excelente en algunos contextos, pero insuficiente en otros como la detecci√≥n de fraudes.
   - Aseg√∫rate de que los criterios de evaluaci√≥n reflejen los objetivos pr√°cticos.

4. **Caracter√≠sticas (Features):**

   - ¬øQu√© partes de nuestros datos ser√°n relevantes para entrenar el modelo?
   - Ejemplo: Para predecir precios de casas, las caracter√≠sticas relevantes podr√≠an incluir ubicaci√≥n, tama√±o y antig√ºedad.
   - ¬øC√≥mo pueden influir nuestros conocimientos previos en la selecci√≥n y creaci√≥n de estas caracter√≠sticas?

5. **Modelado:**

   - ¬øQu√© modelo es el m√°s adecuado para el problema (clasificaci√≥n, regresi√≥n, clustering)?
   - ¬øC√≥mo podemos mejorar el modelo ajustando sus hiperpar√°metros?
   - ¬øC√≥mo se compara este modelo con otros en t√©rminos de m√©tricas y rendimiento?

6. **Experimentaci√≥n:**
   - ¬øQu√© nuevas estrategias, modelos o configuraciones podr√≠amos probar para mejorar los resultados?
   - ¬øEl modelo implementado est√° funcionando como esper√°bamos en producci√≥n?
   - ¬øC√≥mo podr√≠an las observaciones actuales modificar las decisiones en las etapas anteriores?

Esta estructura est√° basada en el [6-Step Field Guide](https://www.mrdbourke.com/a-6-step-field-guide-for-building-machine-learning-projects/).

<img src="/assets/section-2/framework.png" alt="Framework" width="600">

> üîó Estructura completa en [Whimsical](https://whimsical.com/6-step-field-guide-to-machine-learning-projects-flowcharts-9g65jgoRYTxMXxDosndYTB)

---

## **Paso 1: Definici√≥n del Problema**

Definir un problema como de Machine Learning requiere identificar qu√© tipo de aprendizaje y enfoque ser√° m√°s adecuado para abordarlo. A continuaci√≥n, se resumen los tipos principales de aprendizaje y problemas en ML:

### **Tipos de Aprendizaje en ML**

1. **Aprendizaje Supervisado:**

   - Utiliza datos **etiquetados** (inputs con resultados conocidos) para entrenar un modelo que pueda predecir resultados futuros.
   - _Ejemplo: Predecir si un paciente tiene o no una enfermedad card√≠aca, bas√°ndose en historiales m√©dicos etiquetados._
   - El modelo devuelve predicciones probabil√≠sticas, como "70% de probabilidad de tener la enfermedad".

2. **Aprendizaje No Supervisado:**

   - Trabaja con datos **no etiquetados** para identificar patrones o relaciones entre ellos.
   - _Ejemplo: Agrupar clientes de una tienda seg√∫n su historial de compras (clustering). Las etiquetas (categor√≠as) son a√±adidas posteriormente por el experto en dominio._
   - √ötil para descubrimientos en grandes vol√∫menes de datos.

3. **Transfer Learning:**

   - Aprovecha un modelo **previamente entrenado** y lo ajusta a un problema nuevo y espec√≠fico.
   - _Ejemplo: Utilizar un modelo preentrenado en texto (como uno basado en Wikipedia) para clasificar si un reclamo de seguro est√° "a favor" o "en contra" del cliente._

4. **Reinforcement Learning (Aprendizaje por Refuerzo)**:
   - Menos com√∫n en negocios est√°ndar debido a:
     - Requisitos de computaci√≥n
     - Complejidad del dise√±o
     - Largo tiempo de entrenamiento

### **Tipos de Problemas en ML**

1. **Clasificaci√≥n:** _(supervisado)_

   - Predice etiquetas discretas para los datos.
   - Ejemplos:
     - Clasificar correos como "spam" o "no spam" (**binaria**).
     - Determinar niveles como "bajo", "medio", "alto" (**multi-clase**).
     - Asignar m√∫ltiples etiquetas a un dato (**multi-etiqueta**).

2. **Regresi√≥n:**

   - Predice valores num√©ricos continuos.
   - Ejemplo: Estimar el precio de una casa o predecir ventas futuras.

3. **Recomendaci√≥n:**

   - Sugiere elementos personalizados en funci√≥n de datos previos.
   - Ejemplo: Recomendar productos en una tienda online seg√∫n historial de compras.

4. **Clustering:** _(no supervisado)_
   - Agrupa datos no etiquetados en categor√≠as basadas en similitudes.
   - Ejemplo: Segmentar clientes en grupos seg√∫n su comportamiento de compra.

<img src="/assets/section-2/tipos-ml.png" alt="Tipos de problemas en ML" width="600">

### **Ejemplo Aplicado: Reclamos de Seguros**

**Problema:** Un gran n√∫mero de reclamos de seguros est√° llegando m√°s r√°pido de lo que el personal puede manejarlos. Hay datos hist√≥ricos etiquetados que indican si un reclamo fue "con culpa" o "sin culpa".

**Definici√≥n en t√©rminos de ML:**
Queremos clasificar los reclamos como "con culpa" o "sin culpa". Esto convierte el problema en un caso de **clasificaci√≥n supervisada**.

> Para definir un problema de negocio como un problema de Machine Learning:
>
> 1. Reform√∫lalo en t√©rminos simples (p. ej., "¬øpodemos clasificar esto?").
> 2. Decide qu√© tipo de problema es (clasificaci√≥n, regresi√≥n o recomendaci√≥n).
> 3. Define el objetivo inicial en una sola frase y agrega complejidad conforme sea necesario.

---

## **Paso 2: Datos**

- **Estructurados:** Tablas con columnas bien definidas.
- **No estructurados:** Datos complejos como im√°genes, audio o texto.
- **Datos est√°ticos:** Datos hist√≥ricos que rara vez cambian o se actualizan.
- **Datos en streaming**: Datos que se generan y actualizan de manera continua.
- **Datos mixtos:** Combinaci√≥n de datos estructurados y no estructurados.

---

## **Paso 3: Evaluaci√≥n**

La evaluaci√≥n de modelos de Machine Learning es fundamental para determinar su desempe√±o y utilidad en un problema pr√°ctico. Las m√©tricas de evaluaci√≥n var√≠an seg√∫n el tipo de problema: clasificaci√≥n, regresi√≥n o recomendaci√≥n.

### **M√©tricas en Regresi√≥n**

- **MAE (Mean Absolute Error - Error Absoluto Medio)**
  - Promedio de las diferencias absolutas entre las predicciones del modelo y los valores reales.
  - F√≥rmula: \( MAE = \frac{1}{n} \sum\_{i=1}^n | y_i - \hat{y}\_i | \)
- **RMSE (Root Mean Square Error)**
  - Promedio de los errores al cuadrado. Penaliza m√°s los errores grandes.
  - F√≥rmula: \( MSE = \frac{1}{n} \sum\_{i=1}^n (y_i - \hat{y}\_i)^2 \)
- **Ra√≠z del Error Cuadr√°tico Medio (Root Mean Squared Error, RMSE):**
  - Ra√≠z cuadrada del MSE. Penaliza los errores grandes m√°s que el MAE.
  - F√≥rmula: \( RMSE = \sqrt{MSE} \)
- **\( R^2 \) (Coeficiente de determinaci√≥n)**
  - Mide qu√© proporci√≥n de la variabilidad de los datos es explicada por el modelo.
  - Valores cercanos a 1.0 indican un ajuste casi perfecto.

#### **Diferencia entre MAE y RMSE:**

- **MAE:** Trata todos los errores con igual peso.
- **RMSE:** Penaliza m√°s los errores grandes. √ötil cuando estos son cr√≠ticos.

### **M√©tricas en Clasificaci√≥n**

- **Accuracy**
  - Proporci√≥n de predicciones correctas sobre el total.
  - Ejemplo: Si un modelo predice correctamente 90 de 100 correos como "spam" o "no spam", la precisi√≥n es 90%.
- **Precision**
  - Proporci√≥n de predicciones positivas que son realmente correctas.
  - F√≥rmula: \( \text{Precision} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Positives}} \)
  - √ötil cuando es importante minimizar los **falsos positivos** (por ejemplo, predecir una enfermedad que no existe).
- **Recall (sensibilidad)**
  - Proporci√≥n de verdaderos positivos correctamente identificados.
  - F√≥rmula: \( \text{Recall} = \frac{\text{True Positives}}{\text{True Positives} + \text{False Negatives}} \)
  - √ötil cuando es crucial minimizar los **falsos negativos** (por ejemplo, no detectar una enfermedad grave).
- **F1-Score**
  - Promedio arm√≥nico de precisi√≥n y recall. Balancea la importancia de ambas m√©tricas.
  - F√≥rmula: \( F1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}} \)
- **ROC/AUC** (Receiver Operating Characteristic / √Årea bajo la curva)
  - La curva ROC compara la tasa de verdaderos positivos frente a la tasa de falsos positivos a diferentes umbrales.
  - El AUC mide el √°rea bajo la curva ROC:
    - **1.0:** Predicciones perfectas.
    - **0.5:** Modelo aleatorio.
    - **0.0:** Predicciones 100% incorrectas.

#### **Errores Comunes:**

- **Falsos negativos:** Predice "negativo" pero es "positivo".
  - Ejemplo: No detectar un peat√≥n en un sistema de visi√≥n para coches aut√≥nomos.
- **Falsos positivos:** Predice "positivo" pero es "negativo".
  - Ejemplo: Diagnosticar err√≥neamente una enfermedad.

### **M√©tricas en Problemas de Recomendaci√≥n**

Los problemas de recomendaci√≥n presentan desaf√≠os √∫nicos, ya que el objetivo no es solo acertar, sino tambi√©n optimizar el orden de las sugerencias.

- **Precisi√≥n en K (Precision @ K):**

  - Proporci√≥n de recomendaciones correctas dentro de las **K mejores opciones**.
  - Ejemplo: Si un modelo recomienda 5 productos y 3 son relevantes, la precisi√≥n en K es \( \frac{3}{5} = 0.6 \).

- **Cobertura:**

  - Proporci√≥n de elementos del conjunto total que son recomendados al menos una vez.

- **√çndice de Diversidad:**
  - Eval√∫a cu√°n variadas son las recomendaciones. Ayuda a evitar sugerencias repetitivas.

#### **M√©todo de Evaluaci√≥n:**

- **Divisi√≥n Temporal:**
  - Usar datos hist√≥ricos para entrenar el modelo (por ejemplo, datos de 2010-2018).
  - Probar el modelo con datos recientes (2019) para simular su rendimiento en el futuro.

---

### **Elecci√≥n de la M√©trica**

La m√©trica adecuada depende del contexto:

- **Clasificaci√≥n:** Usa F1-Score o AUC si el balance entre precisi√≥n y recall es importante.
- **Regresi√≥n:** Usa MAE si los errores peque√±os son m√°s importantes que los grandes; RMSE si los errores grandes son cr√≠ticos.
- **Recomendaci√≥n:** Usa Precision @ K si el orden de las recomendaciones es relevante.

---

## **Paso 4: Features o Caracter√≠sticas**

Las **features** representan los atributos de los datos que se utilizan para construir un modelo de Machine Learning. Identificar, seleccionar y crear caracter√≠sticas relevantes es crucial para mejorar el rendimiento del modelo. Existen tres tipos principales de caracter√≠sticas:

### **Tipos de Features:**

1. **Categorical (Categ√≥ricas):**

   - Representan categor√≠as o grupos.
   - Ejemplo: Sexo del paciente (hombre/mujer) o si un cliente realiz√≥ una compra (s√≠/no).

2. **Continuous (Continuas o Num√©ricas):**

   - Representan valores num√©ricos.
   - Ejemplo: Frecuencia card√≠aca promedio o n√∫mero de veces que un usuario inici√≥ sesi√≥n.

3. **Derived (Derivadas):**
   - Caracter√≠sticas creadas a partir de los datos existentes mediante ingenier√≠a de caracter√≠sticas (feature engineering).
   - Ejemplo:
     - Combinar fechas y tiempos para calcular "tiempo desde el √∫ltimo inicio de sesi√≥n".
     - Transformar fechas en "d√≠a laboral (s√≠/no)".

<img src="/assets/section-2/features.png" alt="Ejemplo Features" width="600">

### **Consideraciones Importantes:**

- **Consistencia en el entrenamiento y la producci√≥n:** Las caracter√≠sticas utilizadas en la fase de entrenamiento deben representar fielmente las condiciones del entorno real donde se usar√° el modelo.
- **Colaboraci√≥n con expertos en la materia:** Incorporar conocimientos del dominio para identificar y dise√±ar caracter√≠sticas relevantes.
- **Cobertura de datos:** Dar preferencia a caracter√≠sticas que cubran la mayor cantidad de muestras. Si solo un 10% de los datos contienen una caracter√≠stica, podr√≠a no ser √∫til para el modelo.
- **Evitar fugas de datos (feature leakage):** Si el modelo alcanza un rendimiento perfecto, podr√≠a estar utilizando informaci√≥n del conjunto de prueba durante el entrenamiento, lo cual no refleja un uso realista.

#### **Uso de Features en Modelos:**

- **Establecimiento de una l√≠nea base:**
  - Usar conocimiento del dominio para crear predicciones iniciales simples.
  - Ejemplo: "Un cliente que no inicia sesi√≥n en tres semanas tiene un 80% de probabilidad de cancelar su suscripci√≥n".
- **Transformaci√≥n en n√∫meros:**
  - Todas las caracter√≠sticas, incluidas im√°genes o texto, deben convertirse a valores num√©ricos antes de ser utilizadas en un modelo.

> Las caracter√≠sticas son la base de cualquier modelo de Machine Learning. Una buena selecci√≥n y dise√±o de features puede marcar la diferencia entre un modelo mediocre y uno excelente. Este paso requiere tanto conocimientos t√©cnicos como colaboraci√≥n con expertos en el dominio del problema.

---

## **Paso 5: Modelado**

El modelado es el n√∫cleo de Machine Learning y consiste en convertir datos procesados en predicciones √∫tiles. Este proceso se divide en las siguientes etapas:

### **1. **Divisi√≥n de datos (splitting):\*\*

- Separar el conjunto de datos en **entrenamiento**, **validaci√≥n** y **prueba** para evitar sobreajuste.
- Proporci√≥n t√≠pica: 70% entrenamiento, 15% validaci√≥n, 15% prueba.

<img src="/assets/section-2/splitting-data.png" alt="Divisi√≥n de los datos" width="600">

> **Conjunto de datos de entrenamiento:**
>
> - Se utiliza para entrenar el modelo.
> - Lo habitual es asignar el **70-80%** de los datos.
>   **Conjunto de datos de validaci√≥n/desarrollo:**
> - Se utiliza para ajustar los hiperpar√°metros del modelo y evaluar los experimentos.
> - Lo habitual es asignar el **10-15%** de los datos.
>   **Conjunto de datos de prueba:**
> - Se utiliza para probar y comparar el modelo.
> - Lo habitual es asignar el **10-15%** de los datos.

### **2. Elecci√≥n del Modelo _(Training)_**

- Elegir un algoritmo adecuado seg√∫n el tipo de problema (regresi√≥n, clasificaci√≥n, clustering, etc.).
- Seleccionar el modelo adecuado implica considerar los siguientes factores clave:

1. **Interpretabilidad y facilidad de depuraci√≥n:**

   - ¬øPor qu√© el modelo tom√≥ una decisi√≥n espec√≠fica?
   - ¬øQu√© tan f√°cil es identificar y corregir errores?

2. **Cantidad de datos:**

   - ¬øCu√°ntos datos tienes disponibles?
   - ¬øEs probable que esta cantidad aumente en el futuro?

3. **Limitaciones de entrenamiento y predicci√≥n:**
   - ¬øCu√°nto tiempo y recursos computacionales tienes para entrenar y usar el modelo?

> **Recomendaci√≥n:** Comienzar con modelos simples. Los modelos complejos pueden ofrecer mejoras marginales a costa de mayores tiempos de entrenamiento y predicci√≥n.

**Tipos de Modelos:**

- **Modelos lineales (p. ej., regresi√≥n log√≠stica):**

  - R√°pidos, f√°ciles de interpretar y depurar.
  - √ötiles para problemas simples y datos lineales.

- **Modelos basados en √°rboles y boosting (p. ej., [Random Forest](https://towardsdatascience.com/understanding-random-forest-58381e0602d2), [XGBoost](https://xgboost.ai/?ref=mrdbourke.com), [CatBoost](https://catboost.ai/?ref=mrdbourke.com)):**

  - Ideales para datos estructurados (tablas).
  - Suelen ofrecer un buen rendimiento en la mayor√≠a de los casos pr√°cticos.

- **Redes neuronales profundas:**

  - Adecuadas para datos no estructurados (im√°genes, audio, texto).
  - Requieren m√°s recursos y son m√°s dif√≠ciles de depurar, pero son efectivas en problemas complejos.

- **Transfer Learning (aprendizaje por transferencia):**
  - Aprovecha modelos preentrenados (disponibles en plataformas como [PyTorch Hub](https://pytorch.org/hub/?ref=mrdbourke.com), [TensorFlow Hub](https://www.tensorflow.org/hub?ref=mrdbourke.com&hl=es), [ModelZoo](https://modelzoo.co/?ref=mrdbourke.com) y [Fast.ai](https://github.com/fastai/fastai?ref=mrdbourke.com)) para reducir tiempos de entrenamiento y mejorar la eficiencia.
  - Combina las ventajas de los modelos profundos y lineales.

### **3. Mejora y Ajuste del Modelo (Tuning and improving) _(Validation)_**

Los modelos pueden mejorarse ajustando hiperpar√°metros y configuraciones espec√≠ficas. Este proceso se denomina **tuning** y puede incluir:

1. **Hiperpar√°metros:**

   - **Tasa de aprendizaje:** Ajusta la velocidad a la que el modelo aprende.
   - **Optimizador:** Algoritmo que controla c√≥mo se actualizan los pesos del modelo.

2. **Espec√≠fico del modelo:**
   - N√∫mero de √°rboles en Random Forest.
   - N√∫mero y tipo de capas en redes neuronales.

**Automatizaci√≥n:**  
Muchas herramientas modernas automatizan el ajuste de hiperpar√°metros, lo que mejora la eficiencia y reproducibilidad de los modelos.

**Prioridad:**

- **Reproducibilidad:** Documentar los pasos de ajuste para que puedan replicarse.
- **Eficiencia:** Minimizar el tiempo de entrenamiento para probar m√°s ideas r√°pidamente.

### **4. Comparaci√≥n de Modelos _(Test)_**

- Evaluar m√∫ltiples algoritmos y elegir el que mejor se ajuste a los datos con base en m√©tricas relevantes.
- Comparar modelos requiere consistencia en los datos utilizados durante el entrenamiento y la evaluaci√≥n.
- Es recomendable seguir estas reglas:
  - **Entrenar modelos con los mismos datos de entrenamiento (X).**
  - **Evaluarlos con los mismos datos de prueba o validaci√≥n (Y).**
  - **Mantener m√©tricas consistentes:** Comparar modelos con la misma m√©trica de evaluaci√≥n (por ejemplo, accuracy, F1-score, RMSE, etc.).

> **Nota:**
>
> - Cambiar los datos de entrenamiento o validaci√≥n puede generar comparaciones inv√°lidas ("manzanas con naranjas").
> - Aseg√∫rate de que los resultados reflejen las diferencias en los modelos, no en los datos.

---

### **Overfitting vs. Underfitting**

Al entrenar modelos de Machine Learning, el equilibrio entre **overfitting** y **underfitting** es clave para obtener resultados que generalicen bien a nuevos datos. Ambos conceptos representan extremos problem√°ticos en el proceso de modelado:

### **Overfitting**

**Definici√≥n:** Ocurre cuando un modelo se ajusta demasiado a los datos de entrenamiento, aprendiendo incluso patrones irrelevantes o ruido. Como resultado, funciona muy bien con los datos de entrenamiento, pero falla al generalizar con datos nuevos.
**Causas comunes:**

- Modelo **demasiado complejo** para la cantidad o calidad de los datos.
- Uso excesivo de caracter√≠sticas **irrelevantes**.
- Entrenamiento del modelo durante demasiadas iteraciones.
  **Indicadores:**
- Muy baja p√©rdida en el conjunto de entrenamiento pero alta p√©rdida en el conjunto de prueba.
- M√©tricas de evaluaci√≥n significativamente mejores en entrenamiento que en prueba.
  **C√≥mo mitigarlo:**
- Usar regularizaci√≥n (p. ej., L1, L2 o dropout en redes neuronales).
- Simplificar el modelo (menos par√°metros o menos capas en redes profundas).
- Incrementar la cantidad o calidad de los datos de entrenamiento.
- Utilizar t√©cnicas como validaci√≥n cruzada para evaluar el modelo durante el entrenamiento.

### **Underfitting**

**Definici√≥n:** Ocurre cuando el modelo no logra capturar los patrones importantes en los datos. Esto lleva a un desempe√±o pobre tanto en entrenamiento como en prueba.
**Causas comunes:**

- Modelo demasiado **simple** para la complejidad de los datos.
- **Insuficiente** tiempo de entrenamiento o mala configuraci√≥n de hiperpar√°metros.
- Selecci√≥n **incorrecta** de caracter√≠sticas (falta de informaci√≥n relevante).
  **Indicadores:**
- Alta p√©rdida tanto en el conjunto de entrenamiento como en el de prueba.
- M√©tricas de evaluaci√≥n bajas en ambos conjuntos.
  **C√≥mo mitigarlo:**
- Incrementar la complejidad del modelo (m√°s par√°metros o capas).
- Asegurarse de que los datos incluyan suficiente informaci√≥n relevante para el problema.
- Ajustar hiperpar√°metros como la tasa de aprendizaje o la arquitectura del modelo.

#### **Ejemplo Visual**

|                  | **Entrenamiento** | **Prueba**     | **Problema**          |
| ---------------- | ----------------- | -------------- | --------------------- |
| **Overfitting**  | Alta precisi√≥n    | Baja precisi√≥n | Generalizaci√≥n pobre. |
| **Underfitting** | Baja precisi√≥n    | Baja precisi√≥n | Modelo poco √∫til.     |
| **Buen ajuste**  | Alta precisi√≥n    | Alta precisi√≥n | Modelo equilibrado.   |

<img src="/assets/section-2/over-under-fitting.png" alt="Overfitting vs Underfitting" width="600">

> El objetivo en el modelado es **encontrar un balance** donde el modelo capture patrones significativos (evitando underfitting) sin ajustarse en exceso a los datos de entrenamiento (evitando overfitting). T√©cnicas como la **validaci√≥n cruzada, la regularizaci√≥n y una cuidadosa selecci√≥n del modelo** son esenciales para lograr este equilibrio.

### Interpretaci√≥n del rendimiento del modelo

**Bajo rendimiento en los datos de entrenamiento:** El modelo no ha aprendido correctamente y est√° underfitting. Intenta usar un modelo diferente, mejorar el modelo existente ajustando hiperpar√°metros o recopilar m√°s datos.

**Alto rendimiento en los datos de entrenamiento pero bajo rendimiento en los datos de prueba:** Esto indica que el modelo no generaliza bien y podr√≠a estar overfitting los datos de entrenamiento. Intenta usar un modelo m√°s simple o aseg√∫rate de que los datos de prueba sean similares en estilo a los datos de entrenamiento.

**Mejor rendimiento en los datos de prueba que en los datos de entrenamiento:** Esto podr√≠a indicar que los datos de prueba est√°n filtr√°ndose en los datos de entrenamiento (divisi√≥n incorrecta de datos) o que has pasado demasiado tiempo optimizando el modelo para el conjunto de prueba. Aseg√∫rate de mantener siempre separados los conjuntos de entrenamiento y prueba, y evita optimizar el rendimiento del modelo en los datos de prueba (usa los conjuntos de entrenamiento y validaci√≥n para mejorar el modelo).

**Bajo rendimiento en producci√≥n (entorno real):** Esto indica que existe una diferencia entre los datos usados durante el entrenamiento y prueba, y los datos reales en producci√≥n. Aseg√∫rate de que los datos utilizados durante la experimentaci√≥n sean representativos de los datos que el modelo encontrar√° en producci√≥n.

---

## **Paso 6: Experimentaci√≥n y Mejora**

La experimentaci√≥n es esencial para optimizar el rendimiento del modelo. Los aspectos clave incluyen:

1. **Validaci√≥n cruzada (Cross-validation):**

   - Dividir los datos en varios subconjuntos para probar el modelo de manera consistente.

2. **T√©cnicas de b√∫squeda de hiperpar√°metros:**

   - **Grid Search:** Prueba exhaustiva de combinaciones de par√°metros.
   - **Random Search:** Selecci√≥n aleatoria de combinaciones para mayor eficiencia.

3. **Documentaci√≥n de experimentos:**
   - Registrar cambios en par√°metros, m√©tricas y observaciones para an√°lisis comparativo.

---

## **Herramientas y Recursos Clave**

En esta secci√≥n, hemos explorado c√≥mo abordar el modelado de datos en Machine Learning de manera estructurada, utilizando un marco de seis pasos. Para llevar a cabo cada etapa del proceso de manera efectiva, contamos con un conjunto de **herramientas y recursos** esenciales:

#### **Sistema**

- **Anaconda:**

  - Entorno integrado que facilita la gesti√≥n de paquetes y entornos virtuales.
  - Ideal para mantener un espacio de trabajo limpio y organizado durante todo el proyecto.
  - **Uso:** Configuraci√≥n inicial del entorno para la **definici√≥n del problema** y la **preparaci√≥n de datos**.

- **Jupyter Notebook:**
  - Herramienta interactiva para escribir, ejecutar y documentar c√≥digo.
  - Facilita el an√°lisis exploratorio, la experimentaci√≥n y la presentaci√≥n de resultados.
  - **Uso:** Durante la **preparaci√≥n de datos**, la **experimentaci√≥n** y la **visualizaci√≥n** de resultados.

#### **Framework y Gu√≠as**

- **[6-Step Field Guide](https://www.mrdbourke.com/a-6-step-field-guide-for-building-machine-learning-projects/):**
  - Una referencia estructurada para abordar proyectos de Machine Learning.
  - Proporciona un marco claro y repetible para todos los pasos del proceso.

#### **Bibliotecas**

- **Scikit-learn:**

  - Algoritmos cl√°sicos de ML para clasificaci√≥n, regresi√≥n y clustering.
  - Incluye herramientas para dividir datos, ajustar modelos y evaluar resultados.
  - **Uso:** Modelado, ajuste de hiperpar√°metros y comparaci√≥n de modelos.

- **TensorFlow y PyTorch:**

  - Frameworks avanzados para construir y entrenar redes neuronales.
  - TensorFlow es ideal para modelos escalables y producci√≥n; PyTorch es preferido para investigaci√≥n y experimentaci√≥n.
  - **Uso:** Modelado avanzado y experimentaci√≥n con datos no estructurados (im√°genes, texto, audio).

- **Pandas y NumPy:**

  - **Pandas:** Manipulaci√≥n de datos tabulares, limpieza y transformaci√≥n.
  - **NumPy:** C√°lculos num√©ricos eficientes, como operaciones matriciales.
  - **Uso:** En la **preparaci√≥n de datos** y la creaci√≥n de caracter√≠sticas.

- **dmlc XGBoost:**
  - Biblioteca especializada en algoritmos de boosting, ideal para datos estructurados.
  - Ofrece alta precisi√≥n y eficiencia en problemas de clasificaci√≥n y regresi√≥n.
  - **Uso:** Modelado y experimentaci√≥n con algoritmos basados en √°rboles.

#### **Visualizaci√≥n**

- **Matplotlib y Seaborn:**

  - Creaci√≥n de gr√°ficos est√°ticos para an√°lisis y presentaci√≥n.
  - **Uso:** Durante la **exploraci√≥n de datos** y la interpretaci√≥n de resultados.

- **Plotly:**
  - Herramienta de visualizaci√≥n interactiva, √∫til para an√°lisis m√°s din√°micos.
  - **Uso:** Presentaci√≥n de resultados y visualizaci√≥n avanzada en la etapa de **experimentaci√≥n**.

---

## **Recurso Opcional: Elements of AI**

> Un recurso adicional es la p√°gina web de **[Elements of AI](https://www.elementsofai.com/)**. Tiene excelentes explicaciones introductorias de muchos conceptos relacionados con el aprendizaje autom√°tico, la ciencia de datos y la inteligencia artificial.
