# Data Engineering

## 칈ndice

1. [쯈u칠 es Data Engineering?](#쯤u칠-es-data-engineering)
2. [La Figura del Ingeniero de Datos](#la-figura-del-ingeniero-de-datos)
3. [Conceptos Clave en Data Engineering](#conceptos-clave-en-data-engineering)
   - [Data Mining (Miner칤a de Datos)](#1-data-mining-miner칤a-de-datos)
   - [Big Data](#2-big-data)
   - [Data Pipeline](#3-data-pipeline)
4. [Tipos de Datos](#tipos-de-datos)
   - [Datos Estructurados](#1-datos-estructurados)
   - [Datos Semiestructurados](#2-datos-semiestructurados)
   - [Datos No Estructurados](#3-datos-no-estructurados)
   - [Datos Binarios](#4-datos-binarios)
5. [Tipos de Bases de Datos](#tipos-de-bases-de-datos)
6. [Propiedades ACID de una Base de Datos](#propiedades-acid-de-una-base-de-datos)
7. [OLTP y OLAP](#oltp-y-olap)
8. [Hadoop, HDFS y MapReduce](#hadoop-hdfs-y-mapreduce)
9. [Apache Spark y Apache Flink](#apache-spark-y-apache-flink)
10. [Kafka y Stream Processing](#kafka-y-stream-processing)

## 쯈u칠 es Data Engineering?

Data Engineering (Ingenier칤a de Datos) se refiere al **proceso de dise침ar, construir y gestionar sistemas y arquitecturas para recopilar, almacenar y analizar grandes vol칰menes de datos**. Es una disciplina esencial dentro de la Ciencia de Datos y el Big Data, encarg치ndose de que los datos est칠n disponibles, sean confiables y est칠n listos para ser analizados.

Los ingenieros de datos dise침an **pipelines**, integran datos desde m칰ltiples fuentes y aseguran que los sistemas sean escalables y eficientes.

<img src="../assets/section-10/data-engineering.jpg" alt="Qu칠 es Data Engineering" width="600" style="margin: 16px auto; background: white;">

游댕 [Data Engineering - Wikipedia](https://en.wikipedia.org/wiki/Data_engineering)

## La Figura del Ingeniero de Datos

El ingeniero de datos es responsable de construir y optimizar los sistemas que permiten que los datos sean accesibles y 칰tiles para los analistas, cient칤ficos de datos y aplicaciones empresariales. Sus principales responsabilidades incluyen:

1. **Dise침o de Pipelines de Datos:** Creaci칩n de procesos que extraen, transforman y cargan (ETL/ELT) datos desde diversas fuentes hacia almacenes de datos.
2. **Gest칤n de Bases de Datos:** Configuraci칩n, administraci칩n y optimizaci칩n de bases de datos relacionales y no relacionales.
3. **Calidad de los Datos:** Implementaci칩n de procesos para asegurar la integridad, exactitud y consistencia de los datos.
4. **Optimizaci칩n de Rendimiento:** Dise침o de sistemas escalables que puedan manejar grandes vol칰menes de datos y adaptarse al crecimiento.
5. **Automatizaci칩n:** Uso de herramientas y lenguajes como Python, Spark y Airflow para automatizar tareas repetitivas.

## Conceptos Clave en Data Engineering

### 1. Data Mining (Miner칤a de Datos)

Es el proceso de descubrir patrones, relaciones y conocimientos 칰tiles en grandes conjuntos de datos. Utiliza t칠cnicas de estad칤stica, aprendizaje autom치tico y visualizaci칩n para extraer informaci칩n relevante.

**Ejemplo:** Encontrar correlaciones entre las compras de productos en un supermercado para crear ofertas personalizadas.

<img src="../assets/section-10/proceso-mineria-de-datos.webp" alt="Data Mining" width="500" style="padding: 16px; margin: 16px auto; background: white;">

### 2. Big Data

Hace referencia a conjuntos de datos extremadamente grandes y complejos que no pueden ser gestionados con herramientas y m칠todos tradicionales. Sus principales caracter칤sticas son:

- **Volumen:** Cantidad masiva de datos.
- **Velocidad:** Datos generados a gran velocidad.
- **Variedad:** Datos estructurados, no estructurados y semiestructurados.
- **Veracidad:** Calidad y confiabilidad de los datos.

**Ejemplo:** Datos generados por redes sociales, sensores IoT o transacciones financieras.

<img src="../assets/section-10/big-data.jpeg" alt="Big Data" width="600" style="margin: 16px auto; background: white;">

### 3. Data Pipeline

Un data pipeline es una serie de procesos que mueven los datos desde su origen hasta su destino final (almac칠n de datos, dashboard, modelo de machine learning, etc.). Incluye:

- **Extracci칩n:** Captura de datos desde m칰ltiples fuentes.
- **Transformaci칩n:** Limpieza, formateo y enriquecimiento de los datos.
- **Carga:** Inserci칩n de datos en el destino final.

**Ejemplo:** Un pipeline que extrae datos de APIs, los convierte a formato JSON y los carga en un almac칠n como Amazon Redshift.

## Tipos de Datos

### 1. Datos Estructurados

- **Definici칩n:** Datos organizados en filas y columnas, como en bases de datos relacionales.
- **Ejemplo:** Registros de clientes con campos como nombre, edad y correo electr칩nico.
- **Uso:** F치cil de consultar con SQL.

### 2. Datos Semiestructurados

- **Definici칩n:** Datos que no est치n organizados en un formato tabular, pero tienen una estructura definida.
- **Ejemplo:** Archivos JSON, XML, y logs.
- **Uso:** Requiere parsers para convertirlos en formatos estructurados.

### 3. Datos No Estructurados

- **Definici칩n:** Datos sin un formato predefinido.
- **Ejemplo:** Videos, im치genes, audio y textos sin etiquetas.
- **Uso:** Procesados mediante t칠cnicas avanzadas como NLP o visi칩n por computadora.

### 4. Datos Binarios

- **Definici칩n:** Datos codificados en formato binario para el almacenamiento y procesamiento eficiente.
- **Ejemplo:** Archivos de im치genes (JPEG, PNG), videos (MP4) o software ejecutable.
- **Uso:** Procesados directamente por aplicaciones especializadas.

<img src="../assets/section-10/data-types.jpeg" alt="Tipos de Datos" width="600" style="margin: 16px auto; background: white;">

## Tipos de Bases de Datos

1. **Bases de Datos Relacionales (SQL):**
   - Organizan datos en tablas con relaciones definidas.
   - Ejemplos: MySQL, PostgreSQL, Oracle.
   - Uso: Ideal para datos estructurados.
   - **Roles que las usan:**
      - Ingeniero de Software: Para gestionar datos de aplicaciones backend.
      - Desarrollador de Software: CRUD y gesti칩n de datos estructurados.
      - Analista de Datos: Para consultas anal칤ticas y reportes.
      - Business Intelligence: Para generar reportes empresariales

2. **Bases de Datos No Relacionales (NoSQL):**
   - Dise침adas para manejar datos semiestructurados y no estructurados.
   - Tipos: Documentos (MongoDB), Clave-Valor (Redis), Columnar (Cassandra), Grafos (Neo4j).
   - Uso: Datos en tiempo real, escalabilidad horizontal.
   - **Roles que las usan:**
      - Ingeniero de Datos: Para manejar datos semiestructurados y en tiempo real.
      - Desarrollador de Aplicaciones: Datos de configuraci칩n y sincronizaci칩n en tiempo real.
      - Desarrollador M칩vil: Bases de datos como Firebase para aplicaciones m칩viles.
      - Cient칤fico de Datos: Datos semiestructurados para an치lisis avanzado.

3. **Data Warehouses:**
   - Almacenes de datos para an치lisis a gran escala.
   - **Estructura:** Dise침ado para almacenar datos estructurados, organizados en filas y columnas en un formato tabular (como bases de datos relacionales).
   - **Prop칩sito:** Optimizado para el an치lisis de datos hist칩ricos y generaci칩n de informes. Es ideal para consultas r치pidas y an치lisis empresariales.
   - **Procesamiento de Datos:** Los datos se procesan (ETL: extracci칩n, transformaci칩n y carga) antes de almacenarse, lo que asegura calidad, consistencia y formato.
   - **Ejemplos:** Amazon Redshift, Google BigQuery, Snowflake.
   - **Uso:** Analizar tendencias hist칩ricas, generar reportes financieros, estudios de mercado.
   - **Roles que las usan:**
      - Ingeniero de Datos: Para almacenar datos procesados y listos para an치lisis.
      - Analista de Datos: Para realizar an치lisis de grandes vol칰menes de datos hist칩ricos.
      - Business Intelligence: Generar reportes estrat칠gicos y dashboards empresariales.
      - Ingeniero de Machine Learning: Preparaci칩n de datos para modelos.

4. **Data Lakes:**
   - Repositorios para almacenar datos en su forma nativa.
   - **Estructura:** Almacena datos en su forma nativa, ya sean estructurados, semiestructurados (JSON, XML) o no estructurados (im치genes, videos, texto, etc.).
   - **Prop칩sito:** Dise침ado para almacenar grandes vol칰menes de datos sin procesar, que pueden ser usados posteriormente para an치lisis avanzados como machine learning o big data.
   - **Procesamiento de Datos:** Los datos se almacenan tal cual se generan y se procesan solo cuando se necesitan (ELT: extracci칩n, carga y transformaci칩n).
   - **Ejemplo:** Hadoop Distributed File System (HDFS), Amazon S3.
   - **Uso:** An치lisis exploratorio de datos, procesamiento de datos en tiempo real, preparaci칩n de datos para modelos de machine learning.
   - **Roles que las usan:**
      - Ingeniero de Datos: Almacenamiento de datos en bruto para procesamiento futuro.
      - Cient칤fico de Datos: An치lisis exploratorio y preparaci칩n de datos no estructurados.
      - Ingeniero de Machine Learning: Entrenamiento de modelos con grandes vol칰menes de datos no estructurados.

<img src="../assets/section-10/data-types-databases.png" alt="Tipos de Bases de Datos" width="600" style="margin: 16px auto; background: white;">

> 游댕 **Recurso adicional:** [Learn SQL - free online tutorial](https://www.khanacademy.org/computing/computer-programming/sql#concept-intro)

### Diferencias Clave entre Data Warehouses y Data Lakes

| Caracter칤stica       | Data Warehouse            | Data Lake                |
|----------------------|---------------------------|--------------------------|
| **Tipo de datos**    | Estructurados            | Cualquier tipo (sin procesar) |
| **Transformaci칩n**   | Preprocesados (ETL)      | Sin procesar (ELT)       |
| **Prop칩sito**        | An치lisis y reportes      | Almacenamiento masivo, an치lisis avanzado |
| **Formato**          | Tablas relacionales      | Archivos diversos        |
| **Costo**            | Mayor (procesamiento previo) | Menor (almacenamiento simple) |
| **Ejemplos**         | Snowflake, Redshift      | HDFS, Amazon S3          |

<img src="../assets/section-10/data-lake-vs-data-warehouse.png" alt="Diferencias Clave entre Data Warehouses y Data Lakes" width="700" style="margin: 16px auto; background: white;">


## Propiedades ACID de una Base de Datos

**ACID** es el acr칩nimo de **Atomicidad, Consistencia, Aislamiento y Durabilidad**. Estas cuatro propiedades definen las transacciones en bases de datos. Cuando todas se cumplen, garantizan la validez de las transacciones incluso ante fallos del sistema, interrupciones de energ칤a y otros errores.

1. **Atomicidad**: Garantiza que todas las operaciones dentro de una transacci칩n se traten como una unidad 칰nica: todas deben completarse con 칠xito o ninguna se ejecuta.
2. **Consistencia**: Asegura que una transacci칩n lleve la base de datos de un estado v치lido a otro, permitiendo 칰nicamente datos v치lidos y evitando la corrupci칩n. Esta estabilidad se mantiene independientemente de si la transacci칩n tiene 칠xito o falla.
3. **Aislamiento**: Determina c칩mo y cu치ndo los cambios realizados por una transacci칩n son visibles para otras. Si m칰ltiples transacciones ocurren simult치neamente, no afectar치n las ejecuciones de otras. Un aislamiento completo podr칤a significar que una transacci칩n no puede realizar inserciones en una tabla que otra transacci칩n est칠 consultando. Sin embargo, en la pr치ctica, suele haber compromisos entre el aislamiento perfecto y el rendimiento.
4. **Durabilidad**: Garantiza que los resultados de una transacci칩n se almacenen permanentemente en el sistema (como copias de seguridad o registros de transacciones). Las modificaciones deben persistir incluso si ocurre un fallo del sistema o hay una p칠rdida de energ칤a.

### 쯈u칠 es una Base de Datos ACID?

Una base de datos ACID o compatible con ACID es aquella que respeta las propiedades de **Atomicidad, Consistencia, Aislamiento y Durabilidad**.

### Beneficios de las Bases de Datos ACID

- **Cero p칠rdida de datos de clientes** durante fallos del sistema o en la nube.
- **Prevenci칩n de datos incorrectos o duplicados.**
- **Consistencia total**, predictibilidad y fiabilidad en las operaciones.
- **Decisiones empresariales m치s confiables** y reducci칩n de problemas causados por errores en los datos.

### 쯃as Bases de Datos NoSQL son Compatibles con ACID?

Originalmente, las bases de datos NoSQL se dise침aron como soluci칩n para manejar grandes vol칰menes de datos no estructurados y para lograr un procesamiento m치s r치pido. Sin embargo, priorizaron la **disponibilidad** sobre la consistencia, lo que comprometi칩 propiedades como la **atomicidad** y el **aislamiento**.

### 쯃as Bases de Datos SQL Distribuidas son Compatibles con ACID?

S칤, bases de datos SQL distribuidas combinan los beneficios de una base de datos relacional ACID con las ventajas de un sistema distribuido escalable y resiliente, manteniendo garant칤as ACID completas.


>[!NOTE]
> * 游댕 Informaci칩n extra칤da del art칤culo [**ACID Properties of a Database: The Keys to Strong Data Consistency**](https://www.yugabyte.com/acid/)


## OLTP y OLAP

**OLTP (Procesamiento de Transacciones en L칤nea) y OLAP (Procesamiento Anal칤tico en L칤nea)** son dos paradigmas utilizados en bases de datos, con diferencias clave en sus objetivos, caracter칤sticas y aplicaciones.

### OLTP (Online Transaction Processing)

1. **Objetivo:** Manejar un gran n칰mero de transacciones peque침as y frecuentes, como compras, actualizaciones de datos y consultas r치pidas.

2. **Caracter칤sticas:**
   - **Transacciones frecuentes:** Dise침ado para operaciones CRUD (Crear, Leer, Actualizar, Eliminar).
   - **Datos detallados:** Maneja datos en tiempo real con un nivel alto de granularidad.
   - **Alta concurrencia:** Puede soportar m칰ltiples usuarios realizando transacciones simult치neamente.
   - **Velocidad:** Prioriza la rapidez y eficiencia en las operaciones.
   - **Modelo de datos:** Normalizado para evitar redundancias.
   - **ACID:** Cumple estrictamente con las propiedades ACID para garantizar la consistencia y confiabilidad de las transacciones.

3. **Ejemplos de uso:**
   - Sistemas de ventas y compras (e-commerce).
   - Sistemas bancarios para transferencias y pagos.
   - Gesti칩n de inventarios en tiempo real.

4. **Ejemplos de bases de datos:** MySQL, PostgreSQL, SQL Server, Oracle.


### **OLAP (Online Analytical Processing)**

1. **Objetivo:** Realizar an치lisis complejo de grandes vol칰menes de datos para obtener informaci칩n estrat칠gica y generar reportes.

2. **Caracter칤sticas:**
   - **An치lisis multidimensional:** Permite consultas avanzadas y an치lisis de datos desde m칰ltiples perspectivas (dimensiones).
   - **Datos agregados:** Dise침ado para trabajar con datos hist칩ricos, resumidos y estructurados para an치lisis.
   - **Baja concurrencia:** Est치 optimizado para menos usuarios ejecutando consultas m치s complejas.
   - **Modelo de datos:** Desnormalizado, con esquemas estrella o copo de nieve, para facilitar la recuperaci칩n de datos.
   - **Rendimiento:** Priorizado en operaciones de lectura y agregaci칩n, aunque las escrituras pueden ser m치s lentas.
   - **ETL:** Utiliza procesos de Extracci칩n, Transformaci칩n y Carga (ETL) para preparar los datos.

3. **Ejemplos de uso:**
   - Generaci칩n de reportes financieros.
   - An치lisis de tendencias de ventas.
   - Informes de rendimiento empresarial (dashboards de BI).

4. **Ejemplos de bases de datos y herramientas:** Snowflake, Amazon Redshift, Google BigQuery, Tableau.

### **Diferencias Clave entre OLTP y OLAP**

| Caracter칤stica         | OLTP                                      | OLAP                                    |
|------------------------|-------------------------------------------|-----------------------------------------|
| **Objetivo**           | Transacciones r치pidas y frecuentes.       | An치lisis y reportes estrat칠gicos.       |
| **Operaciones**        | CRUD (Crear, Leer, Actualizar, Eliminar). | Consultas complejas y multidimensionales. |
| **Volumen de datos**   | Datos actuales y detallados.              | Datos hist칩ricos y agregados.           |
| **Modelo de datos**    | Normalizado (eficiencia en transacciones).| Desnormalizado (eficiencia en lecturas).|
| **Concurrencia**       | Alta concurrencia de usuarios.            | Baja concurrencia de usuarios.          |
| **Velocidad**          | Optimizado para rapidez en escrituras.    | Optimizado para rapidez en lecturas.    |
| **Usuarios**           | Operadores y usuarios transaccionales.    | Analistas y tomadores de decisiones.    |


> **OLTP** es ideal para operaciones transaccionales y cotidianas, mientras que **OLAP** est치 dise침ado para an치lisis estrat칠gico y toma de decisiones basada en datos hist칩ricos y agregados. Ambos enfoques son complementarios y muchas organizaciones los utilizan en conjunto para gestionar y analizar sus datos de manera efectiva.

> 游댕 **Recurso adicional:** [Diferencia entre OLTP y OLAP](https://techdifferences.com/difference-between-oltp-and-olap.html)


## Hadoop, HDFS y MapReduce

### **Hadoop**

Un marco de c칩digo abierto para almacenar y procesar grandes vol칰menes de datos distribuidos.

**Componentes principales:**

- **HDFS (Hadoop Distributed File System):** Sistema de archivos distribuido que almacena datos en bloques replicados en m칰ltiples nodos.
- **MapReduce:** Modelo de programaci칩n para procesar datos en paralelo.

**Uso:** Procesamiento de Big Data en aplicaciones como an치lisis de logs, predicci칩n del clima y motores de recomendaci칩n.

<img src="../assets/section-10/map-reduce-esquema.png" alt="Hadoop, HDFS y MapReduce" width="600" style="margin: 16px auto; background: white;">

## Apache Spark y Apache Flink

### **Apache Spark**

- Plataforma para procesamiento distribuido de datos.
- **Ventajas:** Procesamiento en memoria, soporte para batch y streaming.
- **Casos de uso:** Machine learning, an치lisis de grafos, ETL.

<img src="../assets/section-10/apache-spark.png" alt="Apache Spark" width="600" style="margin: 16px auto; background: white;">

> * 游댕 [쯈u칠 es Apache Spark? - IBM](https://www.ibm.com/es-es/topics/apache-spark)
> * 游댕 [쯈u칠 es Apache Spark? - Google Cloud](https://cloud.google.com/learn/what-is-apache-spark?hl=es)

### **Apache Flink**

- Plataforma para procesamiento distribuido de datos enfocado en streaming en tiempo real.
- **Ventajas:** Baja latencia, soporte para eventos complejos.
- **Casos de uso:** Detecci칩n de fraudes, monitorizaci칩n en tiempo real.

<img src="../assets/section-10/apache-flink.png" alt="Apache Flink" width="600" style="margin: 16px auto; background: white;">

> 游댕 [Apache Flink - flink.apache.org](https://flink.apache.org/)

## Kafka y Stream Processing

### **Apache Kafka**

- Plataforma distribuida de mensajer칤a para manejar flujos de datos en tiempo real.
- **Caracter칤sticas:** Alta escalabilidad, resiliencia y soporte para integraci칩n con otras herramientas como Spark y Flink.
- **Casos de uso:** Monitorizaci칩n de eventos, integraci칩n de datos en tiempo real.
- [kafka.apache.org](https://kafka.apache.org/)

### **Stream Processing**

- Procesamiento de datos a medida que se generan.
- **Ejemplos de frameworks:** Apache Kafka Streams, [Apache Flink](https://flink.apache.org/), Spark Streaming.
- **Casos de uso:** An치lisis en tiempo real, detecci칩n de anomal칤as.
